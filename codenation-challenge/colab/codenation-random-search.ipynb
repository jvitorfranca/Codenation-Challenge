{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"codenation-random-search.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"2q1xPcky-UEF","colab_type":"code","outputId":"f18d7fbb-a4cd-423c-a4b2-ec278baa49a6","executionInfo":{"status":"ok","timestamp":1555980201990,"user_tz":180,"elapsed":67537,"user":{"displayName":"João Vitor Ferreira França","photoUrl":"","userId":"03674045354190356741"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"cell_type":"code","source":["#conexão com o Google Drive\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","#cria a pasta para manuseio do Google Drive\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 131304 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"pXe93QTC-_VX","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from scipy import stats\n","\n","import sklearn as sk\n","import pandas as pd\n","import numpy as np\n","import pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FJi1NRqN_RKn","colab_type":"code","colab":{}},"cell_type":"code","source":["def process_data(df_train, df_test, df_answer):\n","\n","\tfeatures = list(df_test)\n","\tfeatures.append('NU_NOTA_MT')\n","\n","\tdf_answer['NU_INSCRICAO'] = df_test['NU_INSCRICAO']\n","\n","\tdf_train = df_train[features]\n","\n","\t# Dropando tabelas que não serão utilizadas\n","\n","\tdf_train.drop(['NU_INSCRICAO', 'SG_UF_RESIDENCIA', 'TP_ENSINO', 'TP_DEPENDENCIA_ADM_ESC', 'TP_PRESENCA_CH', 'Q027', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT'], 1, inplace=True)\n","\n","\tdf_test.drop(['NU_INSCRICAO', 'SG_UF_RESIDENCIA', 'TP_ENSINO', 'TP_DEPENDENCIA_ADM_ESC', 'TP_PRESENCA_CH', 'Q027', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT'], 1, inplace=True)\n","\n","\t# Processado dados categóricos\n","\n","\tdf_train['TP_SEXO'].replace('M', 0, inplace=True)\n","\tdf_train['TP_SEXO'].replace('F', 1, inplace=True)\n","\n","\tdf_test['TP_SEXO'].replace('M', 0, inplace=True)\n","\tdf_test['TP_SEXO'].replace('F', 1, inplace=True)\n","\n","\t# Coloquei as notas como zero pq acredito que representam a nota dos alunos que faltaram.\n","\n","\tdf_train['NU_NOTA_CN'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_CH'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_LC'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_MT'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP1'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP2'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP3'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP4'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP5'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_REDACAO'].fillna(0, inplace=True)\n","\n","\tdf_test['NU_NOTA_CN'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_CH'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_LC'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP1'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP2'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP3'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP4'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP5'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_REDACAO'].fillna(0, inplace=True)\n","\n","\t# Coloquei como 8 pq acredito que represente uma situação neutra\n","\n","\tdf_train['TP_STATUS_REDACAO'].fillna(8, inplace=True)\n","\n","\tdf_test['TP_STATUS_REDACAO'].fillna(8, inplace=True)\n","\n","\t# One_hot_enconding em variáveis categóricas\n","\n","\tdf_train = pd.get_dummies(df_train, prefix=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'], columns=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'])\n","\n","\tdf_test = pd.get_dummies(df_test, prefix=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'], columns=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'])\n","\n","\t# Utilizando Estatística Descritiva\n","\n","\tnotas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_REDACAO']\n","\t\n","\tdf_train['KURTOSIS_NOTAS'] = df_train[notas].kurtosis(axis=1)\n","\tdf_train['MEAN_NOTAS'] = df_train[notas].mean(axis=1)\n","\tdf_train['MEDIAN_NOTAS'] = df_train[notas].median(axis=1)\n","\tdf_train['MAD_NOTAS'] = df_train[notas].mad(axis=1)\n","\tdf_train['QUANTILE_NOTAS'] = df_train[notas].quantile(axis=1)\n","\tdf_train['SEM_NOTAS'] = df_train[notas].sem(axis=1)\n","\tdf_train['SKEW_NOTAS'] = df_train[notas].skew(axis=1)\n","\tdf_train['STD_NOTAS'] = df_train[notas].std(axis=1)\n","\tdf_train['VAR_NOTAS'] = df_train[notas].var(axis=1)\n","\tdf_train['AMP_NOTAS'] = df_train[notas].max(axis=1) - df_train[notas].min(axis=1)\n","\t\n","\tdf_train['MEAN_NOTA_CH_LC'] = df_train[['NU_NOTA_CH', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CH_CN'] = df_train[['NU_NOTA_CH', 'NU_NOTA_CN']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CH_REDACAO'] = df_train[['NU_NOTA_CH', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CN_LC'] = df_train[['NU_NOTA_CN', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CN_REDACAO'] = df_train[['NU_NOTA_CN', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_LC_REDACAO'] = df_train[['NU_NOTA_LC', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\t\n","\tnotas_red = ['NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n","\n","\tdf_train['KURTOSIS_NOTAS_COMP'] = df_train[notas_red].kurtosis(axis=1)\n","\tdf_train['MEAN_NOTAS_COMP'] = df_train[notas_red].mean(axis=1)\n","\tdf_train['MEDIAN_NOTAS_COMP'] = df_train[notas_red].median(axis=1)\n","\tdf_train['MAD_NOTAS_COMP'] = df_train[notas_red].mad(axis=1)\n","\tdf_train['QUANTILE_NOTAS_COMP'] = df_train[notas_red].quantile(axis=1)\n","\tdf_train['SEM_NOTAS_COMP'] = df_train[notas_red].sem(axis=1)\n","\tdf_train['STD_NOTAS_COMP'] = df_train[notas_red].std(axis=1)\n","\tdf_train['VAR_NOTAS_COMP'] = df_train[notas_red].var(axis=1)\n","\tdf_train['AMP_NOTAS_COMP'] = df_train[notas_red].max(axis=1) - df_train[notas_red].min(axis=1)\n","\n","\tdf_train['MEAN_NOTA_COMP1_COMP2'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP2']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP1_COMP3'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP1_COMP4'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP1_COMP5'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP2_COMP3'] = df_train[['NU_NOTA_COMP2', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP2_COMP4'] = df_train[['NU_NOTA_COMP2', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP2_COMP5'] = df_train[['NU_NOTA_COMP2', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP3_COMP4'] = df_train[['NU_NOTA_COMP3', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP3_COMP5'] = df_train[['NU_NOTA_COMP3', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP4_COMP5'] = df_train[['NU_NOTA_COMP4', 'NU_NOTA_COMP5']].mean(axis=1)\n","\t\n","\tdf_test['KURTOSIS_NOTAS'] = df_test[notas].kurtosis(axis=1)\n","\tdf_test['MEAN_NOTAS'] = df_test[notas].mean(axis=1)\n","\tdf_test['MEDIAN_NOTAS'] = df_test[notas].median(axis=1)\n","\tdf_test['MAD_NOTAS'] = df_test[notas].mad(axis=1)\n","\tdf_test['QUANTILE_NOTAS'] = df_test[notas].quantile(axis=1)\n","\tdf_test['SEM_NOTAS'] = df_test[notas].sem(axis=1)\n","\tdf_test['SKEW_NOTAS'] = df_test[notas].skew(axis=1)\n","\tdf_test['STD_NOTAS'] = df_test[notas].std(axis=1)\n","\tdf_test['VAR_NOTAS'] = df_test[notas].var(axis=1)\n","\tdf_test['AMP_NOTAS'] = df_test[notas].max(axis=1) - df_test[notas].min(axis=1)\n","\t\n","\tdf_test['MEAN_NOTA_CH_LC'] = df_test[['NU_NOTA_CH', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CH_CN'] = df_test[['NU_NOTA_CH', 'NU_NOTA_CN']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CH_REDACAO'] = df_test[['NU_NOTA_CH', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CN_LC'] = df_test[['NU_NOTA_CN', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CN_REDACAO'] = df_test[['NU_NOTA_CN', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_LC_REDACAO'] = df_test[['NU_NOTA_LC', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\t\n","\tdf_test['KURTOSIS_NOTAS_COMP'] = df_test[notas_red].kurtosis(axis=1)\n","\tdf_test['MEAN_NOTAS_COMP'] = df_test[notas_red].mean(axis=1)\n","\tdf_test['MEDIAN_NOTAS_COMP'] = df_test[notas_red].median(axis=1)\n","\tdf_test['MAD_NOTAS_COMP'] = df_test[notas_red].mad(axis=1)\n","\tdf_test['QUANTILE_NOTAS_COMP'] = df_test[notas_red].quantile(axis=1)\n","\tdf_test['SEM_NOTAS_COMP'] = df_test[notas_red].sem(axis=1)\n","\tdf_test['STD_NOTAS_COMP'] = df_test[notas_red].std(axis=1)\n","\tdf_test['VAR_NOTAS_COMP'] = df_test[notas_red].var(axis=1)\n","\tdf_test['AMP_NOTAS_COMP'] = df_test[notas_red].max(axis=1) - df_test[notas_red].min(axis=1)\n","\n","\tdf_test['MEAN_NOTA_COMP1_COMP2'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP2']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP1_COMP3'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP1_COMP4'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP1_COMP5'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP2_COMP3'] = df_test[['NU_NOTA_COMP2', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP2_COMP4'] = df_test[['NU_NOTA_COMP2', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP2_COMP5'] = df_test[['NU_NOTA_COMP2', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP3_COMP4'] = df_test[['NU_NOTA_COMP3', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP3_COMP5'] = df_test[['NU_NOTA_COMP3', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP4_COMP5'] = df_test[['NU_NOTA_COMP4', 'NU_NOTA_COMP5']].mean(axis=1)\n","\n","\treturn df_train, df_test, df_answer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-xgXxDVl_Vgh","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_to_zero(filename):\n","\n","\tdata = pd.read_csv(filename+'.csv')\n","\n","\tfor i in range(0, data.shape[0]):\n","\t\tif data['NU_NOTA_MT'][i] < 80:\n","\t\t\tdata['NU_NOTA_MT'][i] = 0.00\n","\n","\tdata.to_csv('/content/drive/ML/data-codenation-challenge/answer_with_stats_zscore8.csv', index=False, header=True)\n","\n","\treturn data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oE7-qgt8sDKZ","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_regression\n","\n","def ft_importance(k=50):\n","\n","\tdf_train = pd.read_csv('/content/drive/ML/data-codenation-challenge/train.csv')\n","\tdf_test = pd.read_csv('/content/drive/ML/data-codenation-challenge/test.csv')\n","\tdf_answer = pd.DataFrame()\n","\n","\tdf_train, df_test, df_answer = process_data(df_train, df_test, df_answer)\n","\n","\tlabel = df_train['NU_NOTA_MT']\n","\n","\tdf_train.drop(['NU_NOTA_MT'], axis=1, inplace=True)\n","\n","\t# Apply SelectKBest class to extract top 10 best features\n","\n","\tbestfeatures = SelectKBest(score_func=f_regression, k=k)\n","\n","\tfit = bestfeatures.fit(df_train,label)\n","\t\n","\tdfscores = pd.DataFrame(fit.scores_)\n","\t\n","\tdfcolumns = pd.DataFrame(df_train.columns)\n","\n","\t# Concat two dataframes for better visualization \n","\n","\tfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","\n","\t# Naming the dataframe columns\n","\n","\tfeatureScores.columns = ['Specs','Score']\n","\n","\treturn featureScores.nlargest(k,'Score')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g1QeN0M8_iRJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def random_search(df_train, df_test, df_answer, label):\n","\n","\t# Number of trees in random forest\n","\tn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n","\t# Number of features to consider at every split\n","\tmax_features = ['auto', 'sqrt']\n","\t# Maximum number of levels in tree\n","\tmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","\tmax_depth.append(None)\n","\t# Minimum number of samples required to split a node\n","\tmin_samples_split = [2, 5, 10]\n","\t# Minimum number of samples required at each leaf node\n","\tmin_samples_leaf = [1, 2, 4]\n","\t# Method of selecting samples for training each tree\n","\tbootstrap = [True, False]\n","\t# Create the random grid\n","\trandom_grid = {'n_estimators': n_estimators,\n","\t               'max_features': max_features,\n","\t               'max_depth': max_depth,\n","\t               'min_samples_split': min_samples_split,\n","\t               'min_samples_leaf': min_samples_leaf,\n","\t               'bootstrap': bootstrap}\n","\tprint(random_grid)\n","\n","\t# Use the random grid to search for best hyperparameters\n","\t# First create the base model to tune\n","\trf = RandomForestRegressor()\n","\t# Random search of parameters, using 3 fold cross validation, \n","\t# search across 100 different combinations, and use all available cores\n","\trf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 3, verbose=3, random_state=42, n_jobs = -1)\n","\n","\t# Fit the random search model\n","\trf_random.fit(df_train, label)\n","\n","\tbestRF = rf_random.best_estimator_\n","\t\n","\tprint(bestRF)\n","\t\n","\tpredictions = bestRF.predict(df_test)\n","\n","\tdf_answer['NU_NOTA_MT'] = np.around(predictions,2)\n","\n","\tdf_answer.to_csv('/content/drive/ML/data-codenation-challenge/regressor_answer.csv', index=False, header=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tR5QIWr4_6T8","colab_type":"code","outputId":"99904941-b777-4b09-8d8c-0579d7d623bf","executionInfo":{"status":"ok","timestamp":1555993440962,"user_tz":180,"elapsed":10407048,"user":{"displayName":"João Vitor Ferreira França","photoUrl":"","userId":"03674045354190356741"}},"colab":{"base_uri":"https://localhost:8080/","height":666}},"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/ML/data-codenation-challenge/train.csv')\n","df_test = pd.read_csv('/content/drive/ML/data-codenation-challenge/test.csv')\n","df_answer = pd.DataFrame()\n","\n","df_train, df_test, df_answer = process_data(df_train, df_test, df_answer)\n","\n","z = np.abs(stats.zscore(df_train))\n","\n","nan_values_index = np.isnan(z)\n","\n","z[nan_values_index] = 0\n","\n","df_train = df_train[(z < 8).all(axis=1)]\n","\n","print(df_train.shape)\n","\n","label = df_train['NU_NOTA_MT']\n","\n","df_train.drop(['NU_NOTA_MT'], axis=1, inplace=True)\n","\n","random_search(df_train, df_test, df_answer, label)\n","\n","data = convert_to_zero('/content/drive/ML/data-codenation-challenge/regressor_answer')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  errors=errors)\n","/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6586: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  self._update_inplace(new_data)\n","/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  self._update_inplace(new_data)\n"],"name":"stderr"},{"output_type":"stream","text":["(12660, 114)\n","{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n","Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:2281: RuntimeWarning: invalid value encountered in true_divide\n","  return (a - mns) / sstd\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 45.6min\n","[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 190.9min\n","[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 212.6min finished\n"],"name":"stderr"},{"output_type":"stream","text":["RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n","           max_features='auto', max_leaf_nodes=None,\n","           min_impurity_decrease=0.0, min_impurity_split=None,\n","           min_samples_leaf=4, min_samples_split=5,\n","           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n","           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  import sys\n"],"name":"stderr"}]}]}