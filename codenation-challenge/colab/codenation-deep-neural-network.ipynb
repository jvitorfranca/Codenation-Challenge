{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"codenation-deep-neural-network.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"gPEFzDpjpmc8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"064c860c-6cfe-4034-f13c-2caeb0b09272","executionInfo":{"status":"ok","timestamp":1556030923470,"user_tz":180,"elapsed":105226,"user":{"displayName":"João Vitor Ferreira França","photoUrl":"","userId":"03674045354190356741"}}},"cell_type":"code","source":["#conexão com o Google Drive\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","#cria a pasta para manuseio do Google Drive\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 131304 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"zKXHgZtupvTG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f1e011b6-683d-4012-d5d1-eedecb0840bd","executionInfo":{"status":"ok","timestamp":1556030965776,"user_tz":180,"elapsed":2202,"user":{"displayName":"João Vitor Ferreira França","photoUrl":"","userId":"03674045354190356741"}}},"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error \n","from matplotlib import pyplot as plt\n","import seaborn as sb\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import warnings \n","warnings.filterwarnings('ignore')\n","warnings.filterwarnings('ignore', category=DeprecationWarning)\n","from xgboost import XGBRegressor"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"Yj_ruYxxrFAv","colab_type":"code","colab":{}},"cell_type":"code","source":["def process_data(df_train, df_test, df_answer):\n","\n","\tfeatures = list(df_test)\n","\tfeatures.append('NU_NOTA_MT')\n","\n","\tdf_answer['NU_INSCRICAO'] = df_test['NU_INSCRICAO']\n","\n","\tdf_train = df_train[features]\n","\n","\t# Dropando tabelas que não serão utilizadas\n","\n","\tdf_train.drop(['NU_INSCRICAO', 'SG_UF_RESIDENCIA', 'TP_ENSINO', 'TP_DEPENDENCIA_ADM_ESC', 'TP_PRESENCA_CH', 'Q027', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT'], 1, inplace=True)\n","\n","\tdf_test.drop(['NU_INSCRICAO', 'SG_UF_RESIDENCIA', 'TP_ENSINO', 'TP_DEPENDENCIA_ADM_ESC', 'TP_PRESENCA_CH', 'Q027', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT'], 1, inplace=True)\n","\n","\t# Processado dados categóricos\n","\n","\tdf_train['TP_SEXO'].replace('M', 0, inplace=True)\n","\tdf_train['TP_SEXO'].replace('F', 1, inplace=True)\n","\n","\tdf_test['TP_SEXO'].replace('M', 0, inplace=True)\n","\tdf_test['TP_SEXO'].replace('F', 1, inplace=True)\n","\n","\t# Coloquei as notas como zero pq acredito que representam a nota dos alunos que faltaram.\n","\n","\tdf_train['NU_NOTA_CN'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_CH'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_LC'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_MT'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP1'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP2'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP3'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP4'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_COMP5'].fillna(0, inplace=True)\n","\tdf_train['NU_NOTA_REDACAO'].fillna(0, inplace=True)\n","\n","\tdf_test['NU_NOTA_CN'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_CH'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_LC'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP1'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP2'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP3'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP4'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_COMP5'].fillna(0, inplace=True)\n","\tdf_test['NU_NOTA_REDACAO'].fillna(0, inplace=True)\n","\n","\t# Coloquei como 8 pq acredito que represente uma situação neutra\n","\n","\tdf_train['TP_STATUS_REDACAO'].fillna(8, inplace=True)\n","\n","\tdf_test['TP_STATUS_REDACAO'].fillna(8, inplace=True)\n","\n","\t# One_hot_enconding em variáveis categóricas\n","\n","\tdf_train = pd.get_dummies(df_train, prefix=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'], columns=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'])\n","\n","\tdf_test = pd.get_dummies(df_test, prefix=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'], columns=['Q001', 'Q002', 'Q006', 'Q024', 'Q025', 'Q026', 'Q047'])\n","\n","\t# Utilizando Estatística Descritiva\n","\n","\tnotas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_REDACAO']\n","\t\n","\tdf_train['KURTOSIS_NOTAS'] = df_train[notas].kurtosis(axis=1)\n","\tdf_train['MEAN_NOTAS'] = df_train[notas].mean(axis=1)\n","\tdf_train['MEDIAN_NOTAS'] = df_train[notas].median(axis=1)\n","\tdf_train['MAD_NOTAS'] = df_train[notas].mad(axis=1)\n","\tdf_train['QUANTILE_NOTAS'] = df_train[notas].quantile(axis=1)\n","\tdf_train['SEM_NOTAS'] = df_train[notas].sem(axis=1)\n","\tdf_train['SKEW_NOTAS'] = df_train[notas].skew(axis=1)\n","\tdf_train['STD_NOTAS'] = df_train[notas].std(axis=1)\n","\tdf_train['VAR_NOTAS'] = df_train[notas].var(axis=1)\n","\tdf_train['AMP_NOTAS'] = df_train[notas].max(axis=1) - df_train[notas].min(axis=1)\n","\t\n","\tdf_train['MEAN_NOTA_CH_LC'] = df_train[['NU_NOTA_CH', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CH_CN'] = df_train[['NU_NOTA_CH', 'NU_NOTA_CN']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CH_REDACAO'] = df_train[['NU_NOTA_CH', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CN_LC'] = df_train[['NU_NOTA_CN', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_CN_REDACAO'] = df_train[['NU_NOTA_CN', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_LC_REDACAO'] = df_train[['NU_NOTA_LC', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\t\n","\tnotas_red = ['NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n","\n","\tdf_train['KURTOSIS_NOTAS_COMP'] = df_train[notas_red].kurtosis(axis=1)\n","\tdf_train['MEAN_NOTAS_COMP'] = df_train[notas_red].mean(axis=1)\n","\tdf_train['MEDIAN_NOTAS_COMP'] = df_train[notas_red].median(axis=1)\n","\tdf_train['MAD_NOTAS_COMP'] = df_train[notas_red].mad(axis=1)\n","\tdf_train['QUANTILE_NOTAS_COMP'] = df_train[notas_red].quantile(axis=1)\n","\tdf_train['SEM_NOTAS_COMP'] = df_train[notas_red].sem(axis=1)\n","\tdf_train['STD_NOTAS_COMP'] = df_train[notas_red].std(axis=1)\n","\tdf_train['VAR_NOTAS_COMP'] = df_train[notas_red].var(axis=1)\n","\tdf_train['AMP_NOTAS_COMP'] = df_train[notas_red].max(axis=1) - df_train[notas_red].min(axis=1)\n","\n","\tdf_train['MEAN_NOTA_COMP1_COMP2'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP2']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP1_COMP3'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP1_COMP4'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP1_COMP5'] = df_train[['NU_NOTA_COMP1', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP2_COMP3'] = df_train[['NU_NOTA_COMP2', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP2_COMP4'] = df_train[['NU_NOTA_COMP2', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP2_COMP5'] = df_train[['NU_NOTA_COMP2', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP3_COMP4'] = df_train[['NU_NOTA_COMP3', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP3_COMP5'] = df_train[['NU_NOTA_COMP3', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_train['MEAN_NOTA_COMP4_COMP5'] = df_train[['NU_NOTA_COMP4', 'NU_NOTA_COMP5']].mean(axis=1)\n","\t\n","\tdf_test['KURTOSIS_NOTAS'] = df_test[notas].kurtosis(axis=1)\n","\tdf_test['MEAN_NOTAS'] = df_test[notas].mean(axis=1)\n","\tdf_test['MEDIAN_NOTAS'] = df_test[notas].median(axis=1)\n","\tdf_test['MAD_NOTAS'] = df_test[notas].mad(axis=1)\n","\tdf_test['QUANTILE_NOTAS'] = df_test[notas].quantile(axis=1)\n","\tdf_test['SEM_NOTAS'] = df_test[notas].sem(axis=1)\n","\tdf_test['SKEW_NOTAS'] = df_test[notas].skew(axis=1)\n","\tdf_test['STD_NOTAS'] = df_test[notas].std(axis=1)\n","\tdf_test['VAR_NOTAS'] = df_test[notas].var(axis=1)\n","\tdf_test['AMP_NOTAS'] = df_test[notas].max(axis=1) - df_test[notas].min(axis=1)\n","\t\n","\tdf_test['MEAN_NOTA_CH_LC'] = df_test[['NU_NOTA_CH', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CH_CN'] = df_test[['NU_NOTA_CH', 'NU_NOTA_CN']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CH_REDACAO'] = df_test[['NU_NOTA_CH', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CN_LC'] = df_test[['NU_NOTA_CN', 'NU_NOTA_LC']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_CN_REDACAO'] = df_test[['NU_NOTA_CN', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_LC_REDACAO'] = df_test[['NU_NOTA_LC', 'NU_NOTA_REDACAO']].mean(axis=1)\n","\t\n","\tdf_test['KURTOSIS_NOTAS_COMP'] = df_test[notas_red].kurtosis(axis=1)\n","\tdf_test['MEAN_NOTAS_COMP'] = df_test[notas_red].mean(axis=1)\n","\tdf_test['MEDIAN_NOTAS_COMP'] = df_test[notas_red].median(axis=1)\n","\tdf_test['MAD_NOTAS_COMP'] = df_test[notas_red].mad(axis=1)\n","\tdf_test['QUANTILE_NOTAS_COMP'] = df_test[notas_red].quantile(axis=1)\n","\tdf_test['SEM_NOTAS_COMP'] = df_test[notas_red].sem(axis=1)\n","\tdf_test['STD_NOTAS_COMP'] = df_test[notas_red].std(axis=1)\n","\tdf_test['VAR_NOTAS_COMP'] = df_test[notas_red].var(axis=1)\n","\tdf_test['AMP_NOTAS_COMP'] = df_test[notas_red].max(axis=1) - df_test[notas_red].min(axis=1)\n","\n","\tdf_test['MEAN_NOTA_COMP1_COMP2'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP2']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP1_COMP3'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP1_COMP4'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP1_COMP5'] = df_test[['NU_NOTA_COMP1', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP2_COMP3'] = df_test[['NU_NOTA_COMP2', 'NU_NOTA_COMP3']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP2_COMP4'] = df_test[['NU_NOTA_COMP2', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP2_COMP5'] = df_test[['NU_NOTA_COMP2', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP3_COMP4'] = df_test[['NU_NOTA_COMP3', 'NU_NOTA_COMP4']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP3_COMP5'] = df_test[['NU_NOTA_COMP3', 'NU_NOTA_COMP5']].mean(axis=1)\n","\tdf_test['MEAN_NOTA_COMP4_COMP5'] = df_test[['NU_NOTA_COMP4', 'NU_NOTA_COMP5']].mean(axis=1)\n","\n","\treturn df_train, df_test, df_answer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VyzdYkMrrbQK","colab_type":"code","colab":{}},"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/ML/data-codenation-challenge/train.csv')\n","df_test = pd.read_csv('/content/drive/ML/data-codenation-challenge/test.csv')\n","df_answer = pd.DataFrame()\n","\n","df_train, df_test, df_answer = process_data(df_train, df_test, df_answer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wY_FtphJsuxd","colab_type":"code","colab":{}},"cell_type":"code","source":["label = df_train['NU_NOTA_MT']\n","\n","df_train.drop(['NU_NOTA_MT'], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vwMR96nzrWB2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"47802099-1af6-45a5-e0ba-ea596fbde43f","executionInfo":{"status":"ok","timestamp":1556031410894,"user_tz":180,"elapsed":515,"user":{"displayName":"João Vitor Ferreira França","photoUrl":"","userId":"03674045354190356741"}}},"cell_type":"code","source":["NN_model = Sequential()\n","\n","# The Input Layer :\n","NN_model.add(Dense(128, kernel_initializer='normal',input_dim = df_train.shape[1], activation='relu'))\n","\n","# The Hidden Layers :\n","NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n","NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n","NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n","\n","# The Output Layer :\n","NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n","\n","# Compile the network :\n","NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n","NN_model.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_6 (Dense)              (None, 128)               14592     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 256)               33024     \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 179,457\n","Trainable params: 179,457\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"p95yg1ktrq8k","colab_type":"code","colab":{}},"cell_type":"code","source":["checkpoint_name = '/content/drive/ML/data-codenation-challenge/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n","checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AGjd5ChBr7EN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34122},"outputId":"2339c8dd-765f-4a5c-8ef5-3a668592e71e","executionInfo":{"status":"ok","timestamp":1556032188232,"user_tz":180,"elapsed":766769,"user":{"displayName":"João Vitor Ferreira França","photoUrl":"","userId":"03674045354190356741"}}},"cell_type":"code","source":["NN_model.fit(df_train, label, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 10984 samples, validate on 2746 samples\n","Epoch 1/500\n","10984/10984 [==============================] - 4s 377us/step - loss: 65.1988 - mean_absolute_error: 65.1988 - val_loss: 55.6846 - val_mean_absolute_error: 55.6846\n","\n","Epoch 00001: val_loss improved from inf to 55.68461, saving model to /content/drive/ML/data-codenation-challenge/Weights-001--55.68461.hdf5\n","Epoch 2/500\n","10984/10984 [==============================] - 2s 147us/step - loss: 53.8571 - mean_absolute_error: 53.8571 - val_loss: 51.2488 - val_mean_absolute_error: 51.2488\n","\n","Epoch 00002: val_loss improved from 55.68461 to 51.24883, saving model to /content/drive/ML/data-codenation-challenge/Weights-002--51.24883.hdf5\n","Epoch 3/500\n","10984/10984 [==============================] - 2s 144us/step - loss: 49.6357 - mean_absolute_error: 49.6357 - val_loss: 46.8099 - val_mean_absolute_error: 46.8099\n","\n","Epoch 00003: val_loss improved from 51.24883 to 46.80986, saving model to /content/drive/ML/data-codenation-challenge/Weights-003--46.80986.hdf5\n","Epoch 4/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 48.0268 - mean_absolute_error: 48.0268 - val_loss: 47.5675 - val_mean_absolute_error: 47.5675\n","\n","Epoch 00004: val_loss did not improve from 46.80986\n","Epoch 5/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 47.8441 - mean_absolute_error: 47.8441 - val_loss: 45.2487 - val_mean_absolute_error: 45.2487\n","\n","Epoch 00005: val_loss improved from 46.80986 to 45.24873, saving model to /content/drive/ML/data-codenation-challenge/Weights-005--45.24873.hdf5\n","Epoch 6/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 47.9096 - mean_absolute_error: 47.9096 - val_loss: 45.6142 - val_mean_absolute_error: 45.6142\n","\n","Epoch 00006: val_loss did not improve from 45.24873\n","Epoch 7/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 47.2740 - mean_absolute_error: 47.2740 - val_loss: 47.8195 - val_mean_absolute_error: 47.8195\n","\n","Epoch 00007: val_loss did not improve from 45.24873\n","Epoch 8/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 47.2920 - mean_absolute_error: 47.2920 - val_loss: 46.6497 - val_mean_absolute_error: 46.6497\n","\n","Epoch 00008: val_loss did not improve from 45.24873\n","Epoch 9/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 47.2392 - mean_absolute_error: 47.2392 - val_loss: 50.3221 - val_mean_absolute_error: 50.3221\n","\n","Epoch 00009: val_loss did not improve from 45.24873\n","Epoch 10/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 47.1535 - mean_absolute_error: 47.1535 - val_loss: 58.0928 - val_mean_absolute_error: 58.0928\n","\n","Epoch 00010: val_loss did not improve from 45.24873\n","Epoch 11/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 47.6769 - mean_absolute_error: 47.6769 - val_loss: 45.2412 - val_mean_absolute_error: 45.2412\n","\n","Epoch 00011: val_loss improved from 45.24873 to 45.24119, saving model to /content/drive/ML/data-codenation-challenge/Weights-011--45.24119.hdf5\n","Epoch 12/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 46.4941 - mean_absolute_error: 46.4941 - val_loss: 44.8003 - val_mean_absolute_error: 44.8003\n","\n","Epoch 00012: val_loss improved from 45.24119 to 44.80027, saving model to /content/drive/ML/data-codenation-challenge/Weights-012--44.80027.hdf5\n","Epoch 13/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 46.4804 - mean_absolute_error: 46.4804 - val_loss: 58.6275 - val_mean_absolute_error: 58.6275\n","\n","Epoch 00013: val_loss did not improve from 44.80027\n","Epoch 14/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 47.6280 - mean_absolute_error: 47.6280 - val_loss: 52.9782 - val_mean_absolute_error: 52.9782\n","\n","Epoch 00014: val_loss did not improve from 44.80027\n","Epoch 15/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 47.3006 - mean_absolute_error: 47.3006 - val_loss: 45.5631 - val_mean_absolute_error: 45.5631\n","\n","Epoch 00015: val_loss did not improve from 44.80027\n","Epoch 16/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 46.2985 - mean_absolute_error: 46.2985 - val_loss: 46.8464 - val_mean_absolute_error: 46.8464\n","\n","Epoch 00016: val_loss did not improve from 44.80027\n","Epoch 17/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 47.0231 - mean_absolute_error: 47.0231 - val_loss: 46.3771 - val_mean_absolute_error: 46.3771\n","\n","Epoch 00017: val_loss did not improve from 44.80027\n","Epoch 18/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 46.2740 - mean_absolute_error: 46.2740 - val_loss: 46.7917 - val_mean_absolute_error: 46.7917\n","\n","Epoch 00018: val_loss did not improve from 44.80027\n","Epoch 19/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.9997 - mean_absolute_error: 45.9997 - val_loss: 44.8493 - val_mean_absolute_error: 44.8493\n","\n","Epoch 00019: val_loss did not improve from 44.80027\n","Epoch 20/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.9917 - mean_absolute_error: 45.9917 - val_loss: 50.2850 - val_mean_absolute_error: 50.2850\n","\n","Epoch 00020: val_loss did not improve from 44.80027\n","Epoch 21/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 46.1047 - mean_absolute_error: 46.1047 - val_loss: 45.5460 - val_mean_absolute_error: 45.5460\n","\n","Epoch 00021: val_loss did not improve from 44.80027\n","Epoch 22/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 46.0863 - mean_absolute_error: 46.0863 - val_loss: 45.0767 - val_mean_absolute_error: 45.0767\n","\n","Epoch 00022: val_loss did not improve from 44.80027\n","Epoch 23/500\n","10984/10984 [==============================] - 2s 140us/step - loss: 45.7631 - mean_absolute_error: 45.7631 - val_loss: 45.9180 - val_mean_absolute_error: 45.9180\n","\n","Epoch 00023: val_loss did not improve from 44.80027\n","Epoch 24/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 46.3229 - mean_absolute_error: 46.3229 - val_loss: 46.4948 - val_mean_absolute_error: 46.4948\n","\n","Epoch 00024: val_loss did not improve from 44.80027\n","Epoch 25/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 46.2408 - mean_absolute_error: 46.2408 - val_loss: 45.4762 - val_mean_absolute_error: 45.4762\n","\n","Epoch 00025: val_loss did not improve from 44.80027\n","Epoch 26/500\n","10984/10984 [==============================] - 2s 140us/step - loss: 45.9150 - mean_absolute_error: 45.9150 - val_loss: 44.6555 - val_mean_absolute_error: 44.6555\n","\n","Epoch 00026: val_loss improved from 44.80027 to 44.65554, saving model to /content/drive/ML/data-codenation-challenge/Weights-026--44.65554.hdf5\n","Epoch 27/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.3763 - mean_absolute_error: 45.3763 - val_loss: 46.0630 - val_mean_absolute_error: 46.0630\n","\n","Epoch 00027: val_loss did not improve from 44.65554\n","Epoch 28/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 46.0855 - mean_absolute_error: 46.0855 - val_loss: 44.8330 - val_mean_absolute_error: 44.8330\n","\n","Epoch 00028: val_loss did not improve from 44.65554\n","Epoch 29/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.5499 - mean_absolute_error: 45.5499 - val_loss: 44.7734 - val_mean_absolute_error: 44.7734\n","\n","Epoch 00029: val_loss did not improve from 44.65554\n","Epoch 30/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.7655 - mean_absolute_error: 45.7655 - val_loss: 44.9594 - val_mean_absolute_error: 44.9594\n","\n","Epoch 00030: val_loss did not improve from 44.65554\n","Epoch 31/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.6412 - mean_absolute_error: 45.6412 - val_loss: 45.2683 - val_mean_absolute_error: 45.2683\n","\n","Epoch 00031: val_loss did not improve from 44.65554\n","Epoch 32/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.3805 - mean_absolute_error: 45.3805 - val_loss: 44.5401 - val_mean_absolute_error: 44.5401\n","\n","Epoch 00032: val_loss improved from 44.65554 to 44.54010, saving model to /content/drive/ML/data-codenation-challenge/Weights-032--44.54010.hdf5\n","Epoch 33/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.8836 - mean_absolute_error: 45.8836 - val_loss: 52.4855 - val_mean_absolute_error: 52.4855\n","\n","Epoch 00033: val_loss did not improve from 44.54010\n","Epoch 34/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.2548 - mean_absolute_error: 45.2548 - val_loss: 44.5025 - val_mean_absolute_error: 44.5025\n","\n","Epoch 00034: val_loss improved from 44.54010 to 44.50252, saving model to /content/drive/ML/data-codenation-challenge/Weights-034--44.50252.hdf5\n","Epoch 35/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 46.5449 - mean_absolute_error: 46.5449 - val_loss: 44.4604 - val_mean_absolute_error: 44.4604\n","\n","Epoch 00035: val_loss improved from 44.50252 to 44.46043, saving model to /content/drive/ML/data-codenation-challenge/Weights-035--44.46043.hdf5\n","Epoch 36/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.7867 - mean_absolute_error: 45.7867 - val_loss: 44.7837 - val_mean_absolute_error: 44.7837\n","\n","Epoch 00036: val_loss did not improve from 44.46043\n","Epoch 37/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 45.1273 - mean_absolute_error: 45.1273 - val_loss: 48.6857 - val_mean_absolute_error: 48.6857\n","\n","Epoch 00037: val_loss did not improve from 44.46043\n","Epoch 38/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.4065 - mean_absolute_error: 45.4065 - val_loss: 44.1397 - val_mean_absolute_error: 44.1397\n","\n","Epoch 00038: val_loss improved from 44.46043 to 44.13967, saving model to /content/drive/ML/data-codenation-challenge/Weights-038--44.13967.hdf5\n","Epoch 39/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.8080 - mean_absolute_error: 45.8080 - val_loss: 44.9474 - val_mean_absolute_error: 44.9474\n","\n","Epoch 00039: val_loss did not improve from 44.13967\n","Epoch 40/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.2765 - mean_absolute_error: 45.2765 - val_loss: 45.3995 - val_mean_absolute_error: 45.3995\n","\n","Epoch 00040: val_loss did not improve from 44.13967\n","Epoch 41/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.0884 - mean_absolute_error: 45.0884 - val_loss: 44.4977 - val_mean_absolute_error: 44.4977\n","\n","Epoch 00041: val_loss did not improve from 44.13967\n","Epoch 42/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.2572 - mean_absolute_error: 45.2572 - val_loss: 44.8748 - val_mean_absolute_error: 44.8748\n","\n","Epoch 00042: val_loss did not improve from 44.13967\n","Epoch 43/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.4854 - mean_absolute_error: 45.4854 - val_loss: 44.1768 - val_mean_absolute_error: 44.1768\n","\n","Epoch 00043: val_loss did not improve from 44.13967\n","Epoch 44/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.2698 - mean_absolute_error: 45.2698 - val_loss: 44.3442 - val_mean_absolute_error: 44.3442\n","\n","Epoch 00044: val_loss did not improve from 44.13967\n","Epoch 45/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.4698 - mean_absolute_error: 45.4698 - val_loss: 44.5667 - val_mean_absolute_error: 44.5667\n","\n","Epoch 00045: val_loss did not improve from 44.13967\n","Epoch 46/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.0387 - mean_absolute_error: 45.0387 - val_loss: 45.8246 - val_mean_absolute_error: 45.8246\n","\n","Epoch 00046: val_loss did not improve from 44.13967\n","Epoch 47/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.4173 - mean_absolute_error: 45.4173 - val_loss: 47.0707 - val_mean_absolute_error: 47.0707\n","\n","Epoch 00047: val_loss did not improve from 44.13967\n","Epoch 48/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.3435 - mean_absolute_error: 45.3435 - val_loss: 46.3853 - val_mean_absolute_error: 46.3853\n","\n","Epoch 00048: val_loss did not improve from 44.13967\n","Epoch 49/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.5248 - mean_absolute_error: 45.5248 - val_loss: 44.3415 - val_mean_absolute_error: 44.3415\n","\n","Epoch 00049: val_loss did not improve from 44.13967\n","Epoch 50/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.0195 - mean_absolute_error: 45.0195 - val_loss: 44.2613 - val_mean_absolute_error: 44.2613\n","\n","Epoch 00050: val_loss did not improve from 44.13967\n","Epoch 51/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.1572 - mean_absolute_error: 45.1572 - val_loss: 47.4905 - val_mean_absolute_error: 47.4905\n","\n","Epoch 00051: val_loss did not improve from 44.13967\n","Epoch 52/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.0006 - mean_absolute_error: 45.0006 - val_loss: 45.3213 - val_mean_absolute_error: 45.3213\n","\n","Epoch 00052: val_loss did not improve from 44.13967\n","Epoch 53/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 45.2927 - mean_absolute_error: 45.2927 - val_loss: 52.9047 - val_mean_absolute_error: 52.9047\n","\n","Epoch 00053: val_loss did not improve from 44.13967\n","Epoch 54/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.6530 - mean_absolute_error: 45.6530 - val_loss: 44.1207 - val_mean_absolute_error: 44.1207\n","\n","Epoch 00054: val_loss improved from 44.13967 to 44.12066, saving model to /content/drive/ML/data-codenation-challenge/Weights-054--44.12066.hdf5\n","Epoch 55/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 45.0854 - mean_absolute_error: 45.0854 - val_loss: 47.2569 - val_mean_absolute_error: 47.2569\n","\n","Epoch 00055: val_loss did not improve from 44.12066\n","Epoch 56/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.1372 - mean_absolute_error: 45.1372 - val_loss: 47.2707 - val_mean_absolute_error: 47.2707\n","\n","Epoch 00056: val_loss did not improve from 44.12066\n","Epoch 57/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 44.9713 - mean_absolute_error: 44.9713 - val_loss: 56.0699 - val_mean_absolute_error: 56.0699\n","\n","Epoch 00057: val_loss did not improve from 44.12066\n","Epoch 58/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 45.4547 - mean_absolute_error: 45.4547 - val_loss: 45.8693 - val_mean_absolute_error: 45.8693\n","\n","Epoch 00058: val_loss did not improve from 44.12066\n","Epoch 59/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 45.0605 - mean_absolute_error: 45.0605 - val_loss: 44.8282 - val_mean_absolute_error: 44.8282\n","\n","Epoch 00059: val_loss did not improve from 44.12066\n","Epoch 60/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 45.0925 - mean_absolute_error: 45.0925 - val_loss: 44.5698 - val_mean_absolute_error: 44.5698\n","\n","Epoch 00060: val_loss did not improve from 44.12066\n","Epoch 61/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.0403 - mean_absolute_error: 45.0403 - val_loss: 46.1482 - val_mean_absolute_error: 46.1482\n","\n","Epoch 00061: val_loss did not improve from 44.12066\n","Epoch 62/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.3591 - mean_absolute_error: 45.3591 - val_loss: 45.1188 - val_mean_absolute_error: 45.1188\n","\n","Epoch 00062: val_loss did not improve from 44.12066\n","Epoch 63/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 45.1376 - mean_absolute_error: 45.1376 - val_loss: 43.9677 - val_mean_absolute_error: 43.9677\n","\n","Epoch 00063: val_loss improved from 44.12066 to 43.96765, saving model to /content/drive/ML/data-codenation-challenge/Weights-063--43.96765.hdf5\n","Epoch 64/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.7885 - mean_absolute_error: 44.7885 - val_loss: 45.5379 - val_mean_absolute_error: 45.5379\n","\n","Epoch 00064: val_loss did not improve from 43.96765\n","Epoch 65/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.8542 - mean_absolute_error: 44.8542 - val_loss: 45.2083 - val_mean_absolute_error: 45.2083\n","\n","Epoch 00065: val_loss did not improve from 43.96765\n","Epoch 66/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.9584 - mean_absolute_error: 44.9584 - val_loss: 44.0573 - val_mean_absolute_error: 44.0573\n","\n","Epoch 00066: val_loss did not improve from 43.96765\n","Epoch 67/500\n","10984/10984 [==============================] - 1s 136us/step - loss: 44.8215 - mean_absolute_error: 44.8215 - val_loss: 44.3034 - val_mean_absolute_error: 44.3034\n","\n","Epoch 00067: val_loss did not improve from 43.96765\n","Epoch 68/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 44.9063 - mean_absolute_error: 44.9063 - val_loss: 45.2292 - val_mean_absolute_error: 45.2292\n","\n","Epoch 00068: val_loss did not improve from 43.96765\n","Epoch 69/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 44.8515 - mean_absolute_error: 44.8515 - val_loss: 44.1200 - val_mean_absolute_error: 44.1200\n","\n","Epoch 00069: val_loss did not improve from 43.96765\n","Epoch 70/500\n","10984/10984 [==============================] - 2s 141us/step - loss: 44.9326 - mean_absolute_error: 44.9326 - val_loss: 44.9932 - val_mean_absolute_error: 44.9932\n","\n","Epoch 00070: val_loss did not improve from 43.96765\n","Epoch 71/500\n","10984/10984 [==============================] - 2s 138us/step - loss: 44.8146 - mean_absolute_error: 44.8146 - val_loss: 44.0848 - val_mean_absolute_error: 44.0848\n","\n","Epoch 00071: val_loss did not improve from 43.96765\n","Epoch 72/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 44.5914 - mean_absolute_error: 44.5914 - val_loss: 44.3372 - val_mean_absolute_error: 44.3372\n","\n","Epoch 00072: val_loss did not improve from 43.96765\n","Epoch 73/500\n","10984/10984 [==============================] - 1s 130us/step - loss: 44.7097 - mean_absolute_error: 44.7097 - val_loss: 44.0889 - val_mean_absolute_error: 44.0889\n","\n","Epoch 00073: val_loss did not improve from 43.96765\n","Epoch 74/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.5536 - mean_absolute_error: 44.5536 - val_loss: 45.4483 - val_mean_absolute_error: 45.4483\n","\n","Epoch 00074: val_loss did not improve from 43.96765\n","Epoch 75/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.3634 - mean_absolute_error: 44.3634 - val_loss: 47.8225 - val_mean_absolute_error: 47.8225\n","\n","Epoch 00075: val_loss did not improve from 43.96765\n","Epoch 76/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.4274 - mean_absolute_error: 44.4274 - val_loss: 46.8546 - val_mean_absolute_error: 46.8546\n","\n","Epoch 00076: val_loss did not improve from 43.96765\n","Epoch 77/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 44.4918 - mean_absolute_error: 44.4918 - val_loss: 48.3441 - val_mean_absolute_error: 48.3441\n","\n","Epoch 00077: val_loss did not improve from 43.96765\n","Epoch 78/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.8514 - mean_absolute_error: 44.8514 - val_loss: 44.5593 - val_mean_absolute_error: 44.5593\n","\n","Epoch 00078: val_loss did not improve from 43.96765\n","Epoch 79/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.6208 - mean_absolute_error: 44.6208 - val_loss: 47.2884 - val_mean_absolute_error: 47.2884\n","\n","Epoch 00079: val_loss did not improve from 43.96765\n","Epoch 80/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.5545 - mean_absolute_error: 44.5545 - val_loss: 44.8918 - val_mean_absolute_error: 44.8918\n","\n","Epoch 00080: val_loss did not improve from 43.96765\n","Epoch 81/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.6046 - mean_absolute_error: 44.6046 - val_loss: 44.7365 - val_mean_absolute_error: 44.7365\n","\n","Epoch 00081: val_loss did not improve from 43.96765\n","Epoch 82/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 44.2950 - mean_absolute_error: 44.2950 - val_loss: 45.5424 - val_mean_absolute_error: 45.5424\n","\n","Epoch 00082: val_loss did not improve from 43.96765\n","Epoch 83/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 44.3026 - mean_absolute_error: 44.3026 - val_loss: 45.0103 - val_mean_absolute_error: 45.0103\n","\n","Epoch 00083: val_loss did not improve from 43.96765\n","Epoch 84/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.2141 - mean_absolute_error: 44.2141 - val_loss: 45.9743 - val_mean_absolute_error: 45.9743\n","\n","Epoch 00084: val_loss did not improve from 43.96765\n","Epoch 85/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 45.0203 - mean_absolute_error: 45.0203 - val_loss: 44.6214 - val_mean_absolute_error: 44.6214\n","\n","Epoch 00085: val_loss did not improve from 43.96765\n","Epoch 86/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 44.4365 - mean_absolute_error: 44.4365 - val_loss: 44.6648 - val_mean_absolute_error: 44.6648\n","\n","Epoch 00086: val_loss did not improve from 43.96765\n","Epoch 87/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.7197 - mean_absolute_error: 44.7197 - val_loss: 45.3795 - val_mean_absolute_error: 45.3795\n","\n","Epoch 00087: val_loss did not improve from 43.96765\n","Epoch 88/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.5322 - mean_absolute_error: 44.5322 - val_loss: 45.9380 - val_mean_absolute_error: 45.9380\n","\n","Epoch 00088: val_loss did not improve from 43.96765\n","Epoch 89/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.5361 - mean_absolute_error: 44.5361 - val_loss: 43.7491 - val_mean_absolute_error: 43.7491\n","\n","Epoch 00089: val_loss improved from 43.96765 to 43.74909, saving model to /content/drive/ML/data-codenation-challenge/Weights-089--43.74909.hdf5\n","Epoch 90/500\n","10984/10984 [==============================] - 1s 121us/step - loss: 44.2146 - mean_absolute_error: 44.2146 - val_loss: 44.1373 - val_mean_absolute_error: 44.1373\n","\n","Epoch 00090: val_loss did not improve from 43.74909\n","Epoch 91/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 44.1823 - mean_absolute_error: 44.1823 - val_loss: 44.5013 - val_mean_absolute_error: 44.5013\n","\n","Epoch 00091: val_loss did not improve from 43.74909\n","Epoch 92/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.7873 - mean_absolute_error: 44.7873 - val_loss: 43.7295 - val_mean_absolute_error: 43.7295\n","\n","Epoch 00092: val_loss improved from 43.74909 to 43.72953, saving model to /content/drive/ML/data-codenation-challenge/Weights-092--43.72953.hdf5\n","Epoch 93/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.4617 - mean_absolute_error: 44.4617 - val_loss: 43.8799 - val_mean_absolute_error: 43.8799\n","\n","Epoch 00093: val_loss did not improve from 43.72953\n","Epoch 94/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.0810 - mean_absolute_error: 44.0810 - val_loss: 45.5789 - val_mean_absolute_error: 45.5789\n","\n","Epoch 00094: val_loss did not improve from 43.72953\n","Epoch 95/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.3424 - mean_absolute_error: 44.3424 - val_loss: 46.9228 - val_mean_absolute_error: 46.9228\n","\n","Epoch 00095: val_loss did not improve from 43.72953\n","Epoch 96/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.3039 - mean_absolute_error: 44.3039 - val_loss: 45.1993 - val_mean_absolute_error: 45.1993\n","\n","Epoch 00096: val_loss did not improve from 43.72953\n","Epoch 97/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.2025 - mean_absolute_error: 44.2025 - val_loss: 44.7681 - val_mean_absolute_error: 44.7681\n","\n","Epoch 00097: val_loss did not improve from 43.72953\n","Epoch 98/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.7898 - mean_absolute_error: 44.7898 - val_loss: 45.2161 - val_mean_absolute_error: 45.2161\n","\n","Epoch 00098: val_loss did not improve from 43.72953\n","Epoch 99/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.4154 - mean_absolute_error: 44.4154 - val_loss: 44.8626 - val_mean_absolute_error: 44.8626\n","\n","Epoch 00099: val_loss did not improve from 43.72953\n","Epoch 100/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.3497 - mean_absolute_error: 44.3497 - val_loss: 43.9153 - val_mean_absolute_error: 43.9153\n","\n","Epoch 00100: val_loss did not improve from 43.72953\n","Epoch 101/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.9686 - mean_absolute_error: 43.9686 - val_loss: 44.4946 - val_mean_absolute_error: 44.4946\n","\n","Epoch 00101: val_loss did not improve from 43.72953\n","Epoch 102/500\n","10984/10984 [==============================] - 1s 115us/step - loss: 44.0205 - mean_absolute_error: 44.0205 - val_loss: 44.2088 - val_mean_absolute_error: 44.2088\n","\n","Epoch 00102: val_loss did not improve from 43.72953\n","Epoch 103/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.6565 - mean_absolute_error: 44.6565 - val_loss: 45.9029 - val_mean_absolute_error: 45.9029\n","\n","Epoch 00103: val_loss did not improve from 43.72953\n","Epoch 104/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.9997 - mean_absolute_error: 43.9997 - val_loss: 43.7259 - val_mean_absolute_error: 43.7259\n","\n","Epoch 00104: val_loss improved from 43.72953 to 43.72585, saving model to /content/drive/ML/data-codenation-challenge/Weights-104--43.72585.hdf5\n","Epoch 105/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.7704 - mean_absolute_error: 43.7704 - val_loss: 44.1958 - val_mean_absolute_error: 44.1958\n","\n","Epoch 00105: val_loss did not improve from 43.72585\n","Epoch 106/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.7791 - mean_absolute_error: 43.7791 - val_loss: 44.3283 - val_mean_absolute_error: 44.3283\n","\n","Epoch 00106: val_loss did not improve from 43.72585\n","Epoch 107/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.4727 - mean_absolute_error: 44.4727 - val_loss: 46.5175 - val_mean_absolute_error: 46.5175\n","\n","Epoch 00107: val_loss did not improve from 43.72585\n","Epoch 108/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.9978 - mean_absolute_error: 43.9978 - val_loss: 45.6276 - val_mean_absolute_error: 45.6276\n","\n","Epoch 00108: val_loss did not improve from 43.72585\n","Epoch 109/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.7960 - mean_absolute_error: 43.7960 - val_loss: 44.1222 - val_mean_absolute_error: 44.1222\n","\n","Epoch 00109: val_loss did not improve from 43.72585\n","Epoch 110/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.3201 - mean_absolute_error: 44.3201 - val_loss: 43.5798 - val_mean_absolute_error: 43.5798\n","\n","Epoch 00110: val_loss improved from 43.72585 to 43.57977, saving model to /content/drive/ML/data-codenation-challenge/Weights-110--43.57977.hdf5\n","Epoch 111/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.4700 - mean_absolute_error: 44.4700 - val_loss: 44.8716 - val_mean_absolute_error: 44.8716\n","\n","Epoch 00111: val_loss did not improve from 43.57977\n","Epoch 112/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 44.0193 - mean_absolute_error: 44.0193 - val_loss: 45.3768 - val_mean_absolute_error: 45.3768\n","\n","Epoch 00112: val_loss did not improve from 43.57977\n","Epoch 113/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.8038 - mean_absolute_error: 43.8038 - val_loss: 43.9585 - val_mean_absolute_error: 43.9585\n","\n","Epoch 00113: val_loss did not improve from 43.57977\n","Epoch 114/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.0802 - mean_absolute_error: 44.0802 - val_loss: 43.6479 - val_mean_absolute_error: 43.6479\n","\n","Epoch 00114: val_loss did not improve from 43.57977\n","Epoch 115/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 44.0124 - mean_absolute_error: 44.0124 - val_loss: 44.3990 - val_mean_absolute_error: 44.3990\n","\n","Epoch 00115: val_loss did not improve from 43.57977\n","Epoch 116/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.8753 - mean_absolute_error: 43.8753 - val_loss: 43.9414 - val_mean_absolute_error: 43.9414\n","\n","Epoch 00116: val_loss did not improve from 43.57977\n","Epoch 117/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 44.3700 - mean_absolute_error: 44.3700 - val_loss: 44.0911 - val_mean_absolute_error: 44.0911\n","\n","Epoch 00117: val_loss did not improve from 43.57977\n","Epoch 118/500\n","10984/10984 [==============================] - 1s 127us/step - loss: 44.0374 - mean_absolute_error: 44.0374 - val_loss: 44.3688 - val_mean_absolute_error: 44.3688\n","\n","Epoch 00118: val_loss did not improve from 43.57977\n","Epoch 119/500\n","10984/10984 [==============================] - 2s 138us/step - loss: 44.1592 - mean_absolute_error: 44.1592 - val_loss: 43.8129 - val_mean_absolute_error: 43.8129\n","\n","Epoch 00119: val_loss did not improve from 43.57977\n","Epoch 120/500\n","10984/10984 [==============================] - 1s 136us/step - loss: 43.5502 - mean_absolute_error: 43.5502 - val_loss: 44.2862 - val_mean_absolute_error: 44.2862\n","\n","Epoch 00120: val_loss did not improve from 43.57977\n","Epoch 121/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 43.9393 - mean_absolute_error: 43.9393 - val_loss: 43.8936 - val_mean_absolute_error: 43.8936\n","\n","Epoch 00121: val_loss did not improve from 43.57977\n","Epoch 122/500\n","10984/10984 [==============================] - 2s 138us/step - loss: 44.0010 - mean_absolute_error: 44.0010 - val_loss: 45.6828 - val_mean_absolute_error: 45.6828\n","\n","Epoch 00122: val_loss did not improve from 43.57977\n","Epoch 123/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 44.1682 - mean_absolute_error: 44.1682 - val_loss: 46.5274 - val_mean_absolute_error: 46.5274\n","\n","Epoch 00123: val_loss did not improve from 43.57977\n","Epoch 124/500\n","10984/10984 [==============================] - 1s 136us/step - loss: 43.9204 - mean_absolute_error: 43.9204 - val_loss: 43.7338 - val_mean_absolute_error: 43.7338\n","\n","Epoch 00124: val_loss did not improve from 43.57977\n","Epoch 125/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.9283 - mean_absolute_error: 43.9283 - val_loss: 44.0431 - val_mean_absolute_error: 44.0431\n","\n","Epoch 00125: val_loss did not improve from 43.57977\n","Epoch 126/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 43.6107 - mean_absolute_error: 43.6107 - val_loss: 44.2920 - val_mean_absolute_error: 44.2920\n","\n","Epoch 00126: val_loss did not improve from 43.57977\n","Epoch 127/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.0948 - mean_absolute_error: 44.0948 - val_loss: 44.1215 - val_mean_absolute_error: 44.1215\n","\n","Epoch 00127: val_loss did not improve from 43.57977\n","Epoch 128/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.0938 - mean_absolute_error: 44.0938 - val_loss: 45.0281 - val_mean_absolute_error: 45.0281\n","\n","Epoch 00128: val_loss did not improve from 43.57977\n","Epoch 129/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.0591 - mean_absolute_error: 44.0591 - val_loss: 46.7380 - val_mean_absolute_error: 46.7380\n","\n","Epoch 00129: val_loss did not improve from 43.57977\n","Epoch 130/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.7876 - mean_absolute_error: 43.7876 - val_loss: 45.1692 - val_mean_absolute_error: 45.1692\n","\n","Epoch 00130: val_loss did not improve from 43.57977\n","Epoch 131/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 43.9929 - mean_absolute_error: 43.9929 - val_loss: 43.7485 - val_mean_absolute_error: 43.7485\n","\n","Epoch 00131: val_loss did not improve from 43.57977\n","Epoch 132/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 43.6496 - mean_absolute_error: 43.6496 - val_loss: 43.5197 - val_mean_absolute_error: 43.5197\n","\n","Epoch 00132: val_loss improved from 43.57977 to 43.51971, saving model to /content/drive/ML/data-codenation-challenge/Weights-132--43.51971.hdf5\n","Epoch 133/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.8084 - mean_absolute_error: 43.8084 - val_loss: 44.3331 - val_mean_absolute_error: 44.3331\n","\n","Epoch 00133: val_loss did not improve from 43.51971\n","Epoch 134/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.7704 - mean_absolute_error: 43.7704 - val_loss: 44.1847 - val_mean_absolute_error: 44.1847\n","\n","Epoch 00134: val_loss did not improve from 43.51971\n","Epoch 135/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.6642 - mean_absolute_error: 43.6642 - val_loss: 44.2487 - val_mean_absolute_error: 44.2487\n","\n","Epoch 00135: val_loss did not improve from 43.51971\n","Epoch 136/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.8836 - mean_absolute_error: 43.8836 - val_loss: 45.1332 - val_mean_absolute_error: 45.1332\n","\n","Epoch 00136: val_loss did not improve from 43.51971\n","Epoch 137/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.7717 - mean_absolute_error: 43.7717 - val_loss: 43.9547 - val_mean_absolute_error: 43.9547\n","\n","Epoch 00137: val_loss did not improve from 43.51971\n","Epoch 138/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.3697 - mean_absolute_error: 43.3697 - val_loss: 43.4702 - val_mean_absolute_error: 43.4702\n","\n","Epoch 00138: val_loss improved from 43.51971 to 43.47020, saving model to /content/drive/ML/data-codenation-challenge/Weights-138--43.47020.hdf5\n","Epoch 139/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.8576 - mean_absolute_error: 43.8576 - val_loss: 43.2132 - val_mean_absolute_error: 43.2132\n","\n","Epoch 00139: val_loss improved from 43.47020 to 43.21319, saving model to /content/drive/ML/data-codenation-challenge/Weights-139--43.21319.hdf5\n","Epoch 140/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.8110 - mean_absolute_error: 43.8110 - val_loss: 43.6778 - val_mean_absolute_error: 43.6778\n","\n","Epoch 00140: val_loss did not improve from 43.21319\n","Epoch 141/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.9380 - mean_absolute_error: 43.9380 - val_loss: 44.0816 - val_mean_absolute_error: 44.0816\n","\n","Epoch 00141: val_loss did not improve from 43.21319\n","Epoch 142/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.7763 - mean_absolute_error: 43.7763 - val_loss: 43.2016 - val_mean_absolute_error: 43.2016\n","\n","Epoch 00142: val_loss improved from 43.21319 to 43.20155, saving model to /content/drive/ML/data-codenation-challenge/Weights-142--43.20155.hdf5\n","Epoch 143/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.5236 - mean_absolute_error: 43.5236 - val_loss: 43.5939 - val_mean_absolute_error: 43.5939\n","\n","Epoch 00143: val_loss did not improve from 43.20155\n","Epoch 144/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.8601 - mean_absolute_error: 43.8601 - val_loss: 44.8259 - val_mean_absolute_error: 44.8259\n","\n","Epoch 00144: val_loss did not improve from 43.20155\n","Epoch 145/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.4286 - mean_absolute_error: 43.4286 - val_loss: 45.3314 - val_mean_absolute_error: 45.3314\n","\n","Epoch 00145: val_loss did not improve from 43.20155\n","Epoch 146/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.6627 - mean_absolute_error: 43.6627 - val_loss: 47.0411 - val_mean_absolute_error: 47.0411\n","\n","Epoch 00146: val_loss did not improve from 43.20155\n","Epoch 147/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.5672 - mean_absolute_error: 43.5672 - val_loss: 43.4030 - val_mean_absolute_error: 43.4030\n","\n","Epoch 00147: val_loss did not improve from 43.20155\n","Epoch 148/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.4343 - mean_absolute_error: 43.4343 - val_loss: 44.5745 - val_mean_absolute_error: 44.5745\n","\n","Epoch 00148: val_loss did not improve from 43.20155\n","Epoch 149/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.7841 - mean_absolute_error: 43.7841 - val_loss: 43.8425 - val_mean_absolute_error: 43.8425\n","\n","Epoch 00149: val_loss did not improve from 43.20155\n","Epoch 150/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.5412 - mean_absolute_error: 43.5412 - val_loss: 44.1199 - val_mean_absolute_error: 44.1199\n","\n","Epoch 00150: val_loss did not improve from 43.20155\n","Epoch 151/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.4022 - mean_absolute_error: 43.4022 - val_loss: 43.4828 - val_mean_absolute_error: 43.4828\n","\n","Epoch 00151: val_loss did not improve from 43.20155\n","Epoch 152/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.4162 - mean_absolute_error: 43.4162 - val_loss: 44.0905 - val_mean_absolute_error: 44.0905\n","\n","Epoch 00152: val_loss did not improve from 43.20155\n","Epoch 153/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 44.4485 - mean_absolute_error: 44.4485 - val_loss: 45.2084 - val_mean_absolute_error: 45.2084\n","\n","Epoch 00153: val_loss did not improve from 43.20155\n","Epoch 154/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.8493 - mean_absolute_error: 43.8493 - val_loss: 43.7741 - val_mean_absolute_error: 43.7741\n","\n","Epoch 00154: val_loss did not improve from 43.20155\n","Epoch 155/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.4755 - mean_absolute_error: 43.4755 - val_loss: 43.2046 - val_mean_absolute_error: 43.2046\n","\n","Epoch 00155: val_loss did not improve from 43.20155\n","Epoch 156/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.3639 - mean_absolute_error: 43.3639 - val_loss: 43.3704 - val_mean_absolute_error: 43.3704\n","\n","Epoch 00156: val_loss did not improve from 43.20155\n","Epoch 157/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.8307 - mean_absolute_error: 43.8307 - val_loss: 44.0500 - val_mean_absolute_error: 44.0500\n","\n","Epoch 00157: val_loss did not improve from 43.20155\n","Epoch 158/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.7894 - mean_absolute_error: 43.7894 - val_loss: 44.3437 - val_mean_absolute_error: 44.3437\n","\n","Epoch 00158: val_loss did not improve from 43.20155\n","Epoch 159/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.5062 - mean_absolute_error: 43.5062 - val_loss: 43.5237 - val_mean_absolute_error: 43.5237\n","\n","Epoch 00159: val_loss did not improve from 43.20155\n","Epoch 160/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.6676 - mean_absolute_error: 43.6676 - val_loss: 45.1547 - val_mean_absolute_error: 45.1547\n","\n","Epoch 00160: val_loss did not improve from 43.20155\n","Epoch 161/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.3389 - mean_absolute_error: 43.3389 - val_loss: 43.2354 - val_mean_absolute_error: 43.2354\n","\n","Epoch 00161: val_loss did not improve from 43.20155\n","Epoch 162/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.3545 - mean_absolute_error: 43.3545 - val_loss: 43.8150 - val_mean_absolute_error: 43.8150\n","\n","Epoch 00162: val_loss did not improve from 43.20155\n","Epoch 163/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.5576 - mean_absolute_error: 43.5576 - val_loss: 43.3147 - val_mean_absolute_error: 43.3147\n","\n","Epoch 00163: val_loss did not improve from 43.20155\n","Epoch 164/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.4409 - mean_absolute_error: 43.4409 - val_loss: 43.4183 - val_mean_absolute_error: 43.4183\n","\n","Epoch 00164: val_loss did not improve from 43.20155\n","Epoch 165/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.6043 - mean_absolute_error: 43.6043 - val_loss: 45.1990 - val_mean_absolute_error: 45.1990\n","\n","Epoch 00165: val_loss did not improve from 43.20155\n","Epoch 166/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.7748 - mean_absolute_error: 43.7748 - val_loss: 43.5417 - val_mean_absolute_error: 43.5417\n","\n","Epoch 00166: val_loss did not improve from 43.20155\n","Epoch 167/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.4698 - mean_absolute_error: 43.4698 - val_loss: 48.1577 - val_mean_absolute_error: 48.1577\n","\n","Epoch 00167: val_loss did not improve from 43.20155\n","Epoch 168/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.4344 - mean_absolute_error: 43.4344 - val_loss: 43.0683 - val_mean_absolute_error: 43.0683\n","\n","Epoch 00168: val_loss improved from 43.20155 to 43.06825, saving model to /content/drive/ML/data-codenation-challenge/Weights-168--43.06825.hdf5\n","Epoch 169/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 43.6241 - mean_absolute_error: 43.6241 - val_loss: 43.7866 - val_mean_absolute_error: 43.7866\n","\n","Epoch 00169: val_loss did not improve from 43.06825\n","Epoch 170/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 43.6208 - mean_absolute_error: 43.6208 - val_loss: 44.0430 - val_mean_absolute_error: 44.0430\n","\n","Epoch 00170: val_loss did not improve from 43.06825\n","Epoch 171/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 43.8780 - mean_absolute_error: 43.8780 - val_loss: 43.9663 - val_mean_absolute_error: 43.9663\n","\n","Epoch 00171: val_loss did not improve from 43.06825\n","Epoch 172/500\n","10984/10984 [==============================] - 2s 141us/step - loss: 43.6533 - mean_absolute_error: 43.6533 - val_loss: 44.1540 - val_mean_absolute_error: 44.1540\n","\n","Epoch 00172: val_loss did not improve from 43.06825\n","Epoch 173/500\n","10984/10984 [==============================] - 1s 129us/step - loss: 43.3175 - mean_absolute_error: 43.3175 - val_loss: 44.4263 - val_mean_absolute_error: 44.4263\n","\n","Epoch 00173: val_loss did not improve from 43.06825\n","Epoch 174/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.5666 - mean_absolute_error: 43.5666 - val_loss: 43.7587 - val_mean_absolute_error: 43.7587\n","\n","Epoch 00174: val_loss did not improve from 43.06825\n","Epoch 175/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.1201 - mean_absolute_error: 43.1201 - val_loss: 46.2942 - val_mean_absolute_error: 46.2942\n","\n","Epoch 00175: val_loss did not improve from 43.06825\n","Epoch 176/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.7601 - mean_absolute_error: 43.7601 - val_loss: 43.0306 - val_mean_absolute_error: 43.0306\n","\n","Epoch 00176: val_loss improved from 43.06825 to 43.03057, saving model to /content/drive/ML/data-codenation-challenge/Weights-176--43.03057.hdf5\n","Epoch 177/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.4447 - mean_absolute_error: 43.4447 - val_loss: 44.1147 - val_mean_absolute_error: 44.1147\n","\n","Epoch 00177: val_loss did not improve from 43.03057\n","Epoch 178/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.3283 - mean_absolute_error: 43.3283 - val_loss: 49.3109 - val_mean_absolute_error: 49.3109\n","\n","Epoch 00178: val_loss did not improve from 43.03057\n","Epoch 179/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.6120 - mean_absolute_error: 43.6120 - val_loss: 44.3323 - val_mean_absolute_error: 44.3323\n","\n","Epoch 00179: val_loss did not improve from 43.03057\n","Epoch 180/500\n","10984/10984 [==============================] - 1s 134us/step - loss: 43.5310 - mean_absolute_error: 43.5310 - val_loss: 43.7539 - val_mean_absolute_error: 43.7539\n","\n","Epoch 00180: val_loss did not improve from 43.03057\n","Epoch 181/500\n","10984/10984 [==============================] - 2s 146us/step - loss: 43.6214 - mean_absolute_error: 43.6214 - val_loss: 45.1647 - val_mean_absolute_error: 45.1647\n","\n","Epoch 00181: val_loss did not improve from 43.03057\n","Epoch 182/500\n","10984/10984 [==============================] - 2s 145us/step - loss: 43.2587 - mean_absolute_error: 43.2587 - val_loss: 43.1739 - val_mean_absolute_error: 43.1739\n","\n","Epoch 00182: val_loss did not improve from 43.03057\n","Epoch 183/500\n","10984/10984 [==============================] - 2s 145us/step - loss: 43.4456 - mean_absolute_error: 43.4456 - val_loss: 43.3518 - val_mean_absolute_error: 43.3518\n","\n","Epoch 00183: val_loss did not improve from 43.03057\n","Epoch 184/500\n","10984/10984 [==============================] - 2s 142us/step - loss: 43.1550 - mean_absolute_error: 43.1550 - val_loss: 45.8987 - val_mean_absolute_error: 45.8987\n","\n","Epoch 00184: val_loss did not improve from 43.03057\n","Epoch 185/500\n","10984/10984 [==============================] - 2s 144us/step - loss: 43.6513 - mean_absolute_error: 43.6513 - val_loss: 43.2270 - val_mean_absolute_error: 43.2270\n","\n","Epoch 00185: val_loss did not improve from 43.03057\n","Epoch 186/500\n","10984/10984 [==============================] - 2s 143us/step - loss: 43.2506 - mean_absolute_error: 43.2506 - val_loss: 43.6371 - val_mean_absolute_error: 43.6371\n","\n","Epoch 00186: val_loss did not improve from 43.03057\n","Epoch 187/500\n","10984/10984 [==============================] - 2s 143us/step - loss: 43.5916 - mean_absolute_error: 43.5916 - val_loss: 43.0132 - val_mean_absolute_error: 43.0132\n","\n","Epoch 00187: val_loss improved from 43.03057 to 43.01317, saving model to /content/drive/ML/data-codenation-challenge/Weights-187--43.01317.hdf5\n","Epoch 188/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.2024 - mean_absolute_error: 43.2024 - val_loss: 43.6665 - val_mean_absolute_error: 43.6665\n","\n","Epoch 00188: val_loss did not improve from 43.01317\n","Epoch 189/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.5705 - mean_absolute_error: 43.5705 - val_loss: 45.7449 - val_mean_absolute_error: 45.7449\n","\n","Epoch 00189: val_loss did not improve from 43.01317\n","Epoch 190/500\n","10984/10984 [==============================] - 1s 121us/step - loss: 43.2765 - mean_absolute_error: 43.2765 - val_loss: 44.5795 - val_mean_absolute_error: 44.5795\n","\n","Epoch 00190: val_loss did not improve from 43.01317\n","Epoch 191/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.1486 - mean_absolute_error: 43.1486 - val_loss: 46.4275 - val_mean_absolute_error: 46.4275\n","\n","Epoch 00191: val_loss did not improve from 43.01317\n","Epoch 192/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.1785 - mean_absolute_error: 43.1785 - val_loss: 43.0602 - val_mean_absolute_error: 43.0602\n","\n","Epoch 00192: val_loss did not improve from 43.01317\n","Epoch 193/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.4008 - mean_absolute_error: 43.4008 - val_loss: 44.7334 - val_mean_absolute_error: 44.7334\n","\n","Epoch 00193: val_loss did not improve from 43.01317\n","Epoch 194/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.3436 - mean_absolute_error: 43.3436 - val_loss: 43.3951 - val_mean_absolute_error: 43.3951\n","\n","Epoch 00194: val_loss did not improve from 43.01317\n","Epoch 195/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.1740 - mean_absolute_error: 43.1740 - val_loss: 43.6971 - val_mean_absolute_error: 43.6971\n","\n","Epoch 00195: val_loss did not improve from 43.01317\n","Epoch 196/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.5864 - mean_absolute_error: 43.5864 - val_loss: 44.9049 - val_mean_absolute_error: 44.9049\n","\n","Epoch 00196: val_loss did not improve from 43.01317\n","Epoch 197/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.9618 - mean_absolute_error: 43.9618 - val_loss: 44.4456 - val_mean_absolute_error: 44.4456\n","\n","Epoch 00197: val_loss did not improve from 43.01317\n","Epoch 198/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.2508 - mean_absolute_error: 43.2508 - val_loss: 43.9980 - val_mean_absolute_error: 43.9980\n","\n","Epoch 00198: val_loss did not improve from 43.01317\n","Epoch 199/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.4696 - mean_absolute_error: 43.4696 - val_loss: 47.8608 - val_mean_absolute_error: 47.8608\n","\n","Epoch 00199: val_loss did not improve from 43.01317\n","Epoch 200/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.2655 - mean_absolute_error: 43.2655 - val_loss: 43.7409 - val_mean_absolute_error: 43.7409\n","\n","Epoch 00200: val_loss did not improve from 43.01317\n","Epoch 201/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.5089 - mean_absolute_error: 43.5089 - val_loss: 43.4394 - val_mean_absolute_error: 43.4394\n","\n","Epoch 00201: val_loss did not improve from 43.01317\n","Epoch 202/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.1552 - mean_absolute_error: 43.1552 - val_loss: 45.6716 - val_mean_absolute_error: 45.6716\n","\n","Epoch 00202: val_loss did not improve from 43.01317\n","Epoch 203/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.3801 - mean_absolute_error: 43.3801 - val_loss: 43.9381 - val_mean_absolute_error: 43.9381\n","\n","Epoch 00203: val_loss did not improve from 43.01317\n","Epoch 204/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.0704 - mean_absolute_error: 43.0704 - val_loss: 44.2256 - val_mean_absolute_error: 44.2256\n","\n","Epoch 00204: val_loss did not improve from 43.01317\n","Epoch 205/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.6085 - mean_absolute_error: 43.6085 - val_loss: 43.7098 - val_mean_absolute_error: 43.7098\n","\n","Epoch 00205: val_loss did not improve from 43.01317\n","Epoch 206/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.4534 - mean_absolute_error: 43.4534 - val_loss: 43.2457 - val_mean_absolute_error: 43.2457\n","\n","Epoch 00206: val_loss did not improve from 43.01317\n","Epoch 207/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.2405 - mean_absolute_error: 43.2405 - val_loss: 42.9729 - val_mean_absolute_error: 42.9729\n","\n","Epoch 00207: val_loss improved from 43.01317 to 42.97286, saving model to /content/drive/ML/data-codenation-challenge/Weights-207--42.97286.hdf5\n","Epoch 208/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.2196 - mean_absolute_error: 43.2196 - val_loss: 45.9043 - val_mean_absolute_error: 45.9043\n","\n","Epoch 00208: val_loss did not improve from 42.97286\n","Epoch 209/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.0576 - mean_absolute_error: 43.0576 - val_loss: 43.3465 - val_mean_absolute_error: 43.3465\n","\n","Epoch 00209: val_loss did not improve from 42.97286\n","Epoch 210/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8561 - mean_absolute_error: 42.8561 - val_loss: 42.9235 - val_mean_absolute_error: 42.9235\n","\n","Epoch 00210: val_loss improved from 42.97286 to 42.92348, saving model to /content/drive/ML/data-codenation-challenge/Weights-210--42.92348.hdf5\n","Epoch 211/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.2540 - mean_absolute_error: 43.2540 - val_loss: 43.1164 - val_mean_absolute_error: 43.1164\n","\n","Epoch 00211: val_loss did not improve from 42.92348\n","Epoch 212/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.4102 - mean_absolute_error: 43.4102 - val_loss: 44.0218 - val_mean_absolute_error: 44.0218\n","\n","Epoch 00212: val_loss did not improve from 42.92348\n","Epoch 213/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.0704 - mean_absolute_error: 43.0704 - val_loss: 43.8330 - val_mean_absolute_error: 43.8330\n","\n","Epoch 00213: val_loss did not improve from 42.92348\n","Epoch 214/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8733 - mean_absolute_error: 42.8733 - val_loss: 44.7191 - val_mean_absolute_error: 44.7191\n","\n","Epoch 00214: val_loss did not improve from 42.92348\n","Epoch 215/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.1350 - mean_absolute_error: 43.1350 - val_loss: 43.4850 - val_mean_absolute_error: 43.4850\n","\n","Epoch 00215: val_loss did not improve from 42.92348\n","Epoch 216/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.0177 - mean_absolute_error: 43.0177 - val_loss: 44.3615 - val_mean_absolute_error: 44.3615\n","\n","Epoch 00216: val_loss did not improve from 42.92348\n","Epoch 217/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 43.4094 - mean_absolute_error: 43.4094 - val_loss: 43.3153 - val_mean_absolute_error: 43.3153\n","\n","Epoch 00217: val_loss did not improve from 42.92348\n","Epoch 218/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 43.5603 - mean_absolute_error: 43.5603 - val_loss: 45.0799 - val_mean_absolute_error: 45.0799\n","\n","Epoch 00218: val_loss did not improve from 42.92348\n","Epoch 219/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 43.0891 - mean_absolute_error: 43.0891 - val_loss: 45.7513 - val_mean_absolute_error: 45.7513\n","\n","Epoch 00219: val_loss did not improve from 42.92348\n","Epoch 220/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 43.5189 - mean_absolute_error: 43.5189 - val_loss: 44.5372 - val_mean_absolute_error: 44.5372\n","\n","Epoch 00220: val_loss did not improve from 42.92348\n","Epoch 221/500\n","10984/10984 [==============================] - 1s 136us/step - loss: 43.1714 - mean_absolute_error: 43.1714 - val_loss: 43.4586 - val_mean_absolute_error: 43.4586\n","\n","Epoch 00221: val_loss did not improve from 42.92348\n","Epoch 222/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 43.4573 - mean_absolute_error: 43.4573 - val_loss: 46.4655 - val_mean_absolute_error: 46.4655\n","\n","Epoch 00222: val_loss did not improve from 42.92348\n","Epoch 223/500\n","10984/10984 [==============================] - 1s 127us/step - loss: 43.5634 - mean_absolute_error: 43.5634 - val_loss: 44.5047 - val_mean_absolute_error: 44.5047\n","\n","Epoch 00223: val_loss did not improve from 42.92348\n","Epoch 224/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.4236 - mean_absolute_error: 43.4236 - val_loss: 43.5404 - val_mean_absolute_error: 43.5404\n","\n","Epoch 00224: val_loss did not improve from 42.92348\n","Epoch 225/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.0695 - mean_absolute_error: 43.0695 - val_loss: 45.1632 - val_mean_absolute_error: 45.1632\n","\n","Epoch 00225: val_loss did not improve from 42.92348\n","Epoch 226/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.0158 - mean_absolute_error: 43.0158 - val_loss: 43.1756 - val_mean_absolute_error: 43.1756\n","\n","Epoch 00226: val_loss did not improve from 42.92348\n","Epoch 227/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.0282 - mean_absolute_error: 43.0282 - val_loss: 44.1231 - val_mean_absolute_error: 44.1231\n","\n","Epoch 00227: val_loss did not improve from 42.92348\n","Epoch 228/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.3118 - mean_absolute_error: 43.3118 - val_loss: 42.9121 - val_mean_absolute_error: 42.9121\n","\n","Epoch 00228: val_loss improved from 42.92348 to 42.91207, saving model to /content/drive/ML/data-codenation-challenge/Weights-228--42.91207.hdf5\n","Epoch 229/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.9295 - mean_absolute_error: 42.9295 - val_loss: 43.1194 - val_mean_absolute_error: 43.1194\n","\n","Epoch 00229: val_loss did not improve from 42.91207\n","Epoch 230/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.2071 - mean_absolute_error: 43.2071 - val_loss: 43.7714 - val_mean_absolute_error: 43.7714\n","\n","Epoch 00230: val_loss did not improve from 42.91207\n","Epoch 231/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.0104 - mean_absolute_error: 43.0104 - val_loss: 42.9704 - val_mean_absolute_error: 42.9704\n","\n","Epoch 00231: val_loss did not improve from 42.91207\n","Epoch 232/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.3281 - mean_absolute_error: 43.3281 - val_loss: 43.1599 - val_mean_absolute_error: 43.1599\n","\n","Epoch 00232: val_loss did not improve from 42.91207\n","Epoch 233/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.2083 - mean_absolute_error: 43.2083 - val_loss: 43.2141 - val_mean_absolute_error: 43.2141\n","\n","Epoch 00233: val_loss did not improve from 42.91207\n","Epoch 234/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9918 - mean_absolute_error: 42.9918 - val_loss: 43.7834 - val_mean_absolute_error: 43.7834\n","\n","Epoch 00234: val_loss did not improve from 42.91207\n","Epoch 235/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.0757 - mean_absolute_error: 43.0757 - val_loss: 43.0361 - val_mean_absolute_error: 43.0361\n","\n","Epoch 00235: val_loss did not improve from 42.91207\n","Epoch 236/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.0114 - mean_absolute_error: 43.0114 - val_loss: 46.2296 - val_mean_absolute_error: 46.2296\n","\n","Epoch 00236: val_loss did not improve from 42.91207\n","Epoch 237/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.1522 - mean_absolute_error: 43.1522 - val_loss: 43.4146 - val_mean_absolute_error: 43.4146\n","\n","Epoch 00237: val_loss did not improve from 42.91207\n","Epoch 238/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.7408 - mean_absolute_error: 42.7408 - val_loss: 43.3184 - val_mean_absolute_error: 43.3184\n","\n","Epoch 00238: val_loss did not improve from 42.91207\n","Epoch 239/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8948 - mean_absolute_error: 42.8948 - val_loss: 43.5756 - val_mean_absolute_error: 43.5756\n","\n","Epoch 00239: val_loss did not improve from 42.91207\n","Epoch 240/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.2661 - mean_absolute_error: 43.2661 - val_loss: 43.0746 - val_mean_absolute_error: 43.0746\n","\n","Epoch 00240: val_loss did not improve from 42.91207\n","Epoch 241/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.9210 - mean_absolute_error: 42.9210 - val_loss: 45.2703 - val_mean_absolute_error: 45.2703\n","\n","Epoch 00241: val_loss did not improve from 42.91207\n","Epoch 242/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.0445 - mean_absolute_error: 43.0445 - val_loss: 44.8317 - val_mean_absolute_error: 44.8317\n","\n","Epoch 00242: val_loss did not improve from 42.91207\n","Epoch 243/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.2650 - mean_absolute_error: 43.2650 - val_loss: 45.1553 - val_mean_absolute_error: 45.1553\n","\n","Epoch 00243: val_loss did not improve from 42.91207\n","Epoch 244/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8047 - mean_absolute_error: 42.8047 - val_loss: 44.3685 - val_mean_absolute_error: 44.3685\n","\n","Epoch 00244: val_loss did not improve from 42.91207\n","Epoch 245/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.2983 - mean_absolute_error: 43.2983 - val_loss: 47.0623 - val_mean_absolute_error: 47.0623\n","\n","Epoch 00245: val_loss did not improve from 42.91207\n","Epoch 246/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.3110 - mean_absolute_error: 43.3110 - val_loss: 44.3622 - val_mean_absolute_error: 44.3622\n","\n","Epoch 00246: val_loss did not improve from 42.91207\n","Epoch 247/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.3120 - mean_absolute_error: 43.3120 - val_loss: 46.8457 - val_mean_absolute_error: 46.8457\n","\n","Epoch 00247: val_loss did not improve from 42.91207\n","Epoch 248/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7171 - mean_absolute_error: 42.7171 - val_loss: 43.0463 - val_mean_absolute_error: 43.0463\n","\n","Epoch 00248: val_loss did not improve from 42.91207\n","Epoch 249/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8244 - mean_absolute_error: 42.8244 - val_loss: 43.6738 - val_mean_absolute_error: 43.6738\n","\n","Epoch 00249: val_loss did not improve from 42.91207\n","Epoch 250/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.3157 - mean_absolute_error: 43.3157 - val_loss: 43.9239 - val_mean_absolute_error: 43.9239\n","\n","Epoch 00250: val_loss did not improve from 42.91207\n","Epoch 251/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7023 - mean_absolute_error: 42.7023 - val_loss: 43.4130 - val_mean_absolute_error: 43.4130\n","\n","Epoch 00251: val_loss did not improve from 42.91207\n","Epoch 252/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.1654 - mean_absolute_error: 43.1654 - val_loss: 44.8241 - val_mean_absolute_error: 44.8241\n","\n","Epoch 00252: val_loss did not improve from 42.91207\n","Epoch 253/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 42.9111 - mean_absolute_error: 42.9111 - val_loss: 43.1675 - val_mean_absolute_error: 43.1675\n","\n","Epoch 00253: val_loss did not improve from 42.91207\n","Epoch 254/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.0107 - mean_absolute_error: 43.0107 - val_loss: 43.4836 - val_mean_absolute_error: 43.4836\n","\n","Epoch 00254: val_loss did not improve from 42.91207\n","Epoch 255/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.9994 - mean_absolute_error: 42.9994 - val_loss: 44.7060 - val_mean_absolute_error: 44.7060\n","\n","Epoch 00255: val_loss did not improve from 42.91207\n","Epoch 256/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.3986 - mean_absolute_error: 43.3986 - val_loss: 43.8521 - val_mean_absolute_error: 43.8521\n","\n","Epoch 00256: val_loss did not improve from 42.91207\n","Epoch 257/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.9653 - mean_absolute_error: 42.9653 - val_loss: 43.8007 - val_mean_absolute_error: 43.8007\n","\n","Epoch 00257: val_loss did not improve from 42.91207\n","Epoch 258/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.9022 - mean_absolute_error: 42.9022 - val_loss: 44.9197 - val_mean_absolute_error: 44.9197\n","\n","Epoch 00258: val_loss did not improve from 42.91207\n","Epoch 259/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9308 - mean_absolute_error: 42.9308 - val_loss: 44.5813 - val_mean_absolute_error: 44.5813\n","\n","Epoch 00259: val_loss did not improve from 42.91207\n","Epoch 260/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.1071 - mean_absolute_error: 43.1071 - val_loss: 44.2753 - val_mean_absolute_error: 44.2753\n","\n","Epoch 00260: val_loss did not improve from 42.91207\n","Epoch 261/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.0742 - mean_absolute_error: 43.0742 - val_loss: 43.3347 - val_mean_absolute_error: 43.3347\n","\n","Epoch 00261: val_loss did not improve from 42.91207\n","Epoch 262/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.3601 - mean_absolute_error: 43.3601 - val_loss: 43.4056 - val_mean_absolute_error: 43.4056\n","\n","Epoch 00262: val_loss did not improve from 42.91207\n","Epoch 263/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.9338 - mean_absolute_error: 42.9338 - val_loss: 43.4954 - val_mean_absolute_error: 43.4954\n","\n","Epoch 00263: val_loss did not improve from 42.91207\n","Epoch 264/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.7695 - mean_absolute_error: 42.7695 - val_loss: 43.8700 - val_mean_absolute_error: 43.8700\n","\n","Epoch 00264: val_loss did not improve from 42.91207\n","Epoch 265/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.0995 - mean_absolute_error: 43.0995 - val_loss: 43.0021 - val_mean_absolute_error: 43.0021\n","\n","Epoch 00265: val_loss did not improve from 42.91207\n","Epoch 266/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6345 - mean_absolute_error: 42.6345 - val_loss: 42.9805 - val_mean_absolute_error: 42.9805\n","\n","Epoch 00266: val_loss did not improve from 42.91207\n","Epoch 267/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9975 - mean_absolute_error: 42.9975 - val_loss: 43.7212 - val_mean_absolute_error: 43.7212\n","\n","Epoch 00267: val_loss did not improve from 42.91207\n","Epoch 268/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8284 - mean_absolute_error: 42.8284 - val_loss: 43.3701 - val_mean_absolute_error: 43.3701\n","\n","Epoch 00268: val_loss did not improve from 42.91207\n","Epoch 269/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.1778 - mean_absolute_error: 43.1778 - val_loss: 47.6741 - val_mean_absolute_error: 47.6741\n","\n","Epoch 00269: val_loss did not improve from 42.91207\n","Epoch 270/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.1302 - mean_absolute_error: 43.1302 - val_loss: 44.6619 - val_mean_absolute_error: 44.6619\n","\n","Epoch 00270: val_loss did not improve from 42.91207\n","Epoch 271/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6619 - mean_absolute_error: 42.6619 - val_loss: 43.6195 - val_mean_absolute_error: 43.6195\n","\n","Epoch 00271: val_loss did not improve from 42.91207\n","Epoch 272/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9100 - mean_absolute_error: 42.9100 - val_loss: 43.9613 - val_mean_absolute_error: 43.9613\n","\n","Epoch 00272: val_loss did not improve from 42.91207\n","Epoch 273/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9244 - mean_absolute_error: 42.9244 - val_loss: 43.7315 - val_mean_absolute_error: 43.7315\n","\n","Epoch 00273: val_loss did not improve from 42.91207\n","Epoch 274/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.9509 - mean_absolute_error: 42.9509 - val_loss: 43.7448 - val_mean_absolute_error: 43.7448\n","\n","Epoch 00274: val_loss did not improve from 42.91207\n","Epoch 275/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.0328 - mean_absolute_error: 43.0328 - val_loss: 43.2944 - val_mean_absolute_error: 43.2944\n","\n","Epoch 00275: val_loss did not improve from 42.91207\n","Epoch 276/500\n","10984/10984 [==============================] - 2s 138us/step - loss: 44.2878 - mean_absolute_error: 44.2878 - val_loss: 43.6494 - val_mean_absolute_error: 43.6494\n","\n","Epoch 00276: val_loss did not improve from 42.91207\n","Epoch 277/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 43.0484 - mean_absolute_error: 43.0484 - val_loss: 44.7602 - val_mean_absolute_error: 44.7602\n","\n","Epoch 00277: val_loss did not improve from 42.91207\n","Epoch 278/500\n","10984/10984 [==============================] - 2s 138us/step - loss: 42.8188 - mean_absolute_error: 42.8188 - val_loss: 43.6442 - val_mean_absolute_error: 43.6442\n","\n","Epoch 00278: val_loss did not improve from 42.91207\n","Epoch 279/500\n","10984/10984 [==============================] - 1s 136us/step - loss: 42.7235 - mean_absolute_error: 42.7235 - val_loss: 45.2156 - val_mean_absolute_error: 45.2156\n","\n","Epoch 00279: val_loss did not improve from 42.91207\n","Epoch 280/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 42.9270 - mean_absolute_error: 42.9270 - val_loss: 43.0886 - val_mean_absolute_error: 43.0886\n","\n","Epoch 00280: val_loss did not improve from 42.91207\n","Epoch 281/500\n","10984/10984 [==============================] - 1s 136us/step - loss: 42.5651 - mean_absolute_error: 42.5651 - val_loss: 43.5594 - val_mean_absolute_error: 43.5594\n","\n","Epoch 00281: val_loss did not improve from 42.91207\n","Epoch 282/500\n","10984/10984 [==============================] - 1s 127us/step - loss: 42.8818 - mean_absolute_error: 42.8818 - val_loss: 43.0877 - val_mean_absolute_error: 43.0877\n","\n","Epoch 00282: val_loss did not improve from 42.91207\n","Epoch 283/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.0025 - mean_absolute_error: 43.0025 - val_loss: 43.1090 - val_mean_absolute_error: 43.1090\n","\n","Epoch 00283: val_loss did not improve from 42.91207\n","Epoch 284/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 43.1600 - mean_absolute_error: 43.1600 - val_loss: 43.2942 - val_mean_absolute_error: 43.2942\n","\n","Epoch 00284: val_loss did not improve from 42.91207\n","Epoch 285/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.7656 - mean_absolute_error: 42.7656 - val_loss: 43.7724 - val_mean_absolute_error: 43.7724\n","\n","Epoch 00285: val_loss did not improve from 42.91207\n","Epoch 286/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.8720 - mean_absolute_error: 42.8720 - val_loss: 43.5278 - val_mean_absolute_error: 43.5278\n","\n","Epoch 00286: val_loss did not improve from 42.91207\n","Epoch 287/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.7548 - mean_absolute_error: 42.7548 - val_loss: 45.0516 - val_mean_absolute_error: 45.0516\n","\n","Epoch 00287: val_loss did not improve from 42.91207\n","Epoch 288/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 42.9000 - mean_absolute_error: 42.9000 - val_loss: 43.4126 - val_mean_absolute_error: 43.4126\n","\n","Epoch 00288: val_loss did not improve from 42.91207\n","Epoch 289/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.7934 - mean_absolute_error: 42.7934 - val_loss: 43.1460 - val_mean_absolute_error: 43.1460\n","\n","Epoch 00289: val_loss did not improve from 42.91207\n","Epoch 290/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7262 - mean_absolute_error: 42.7262 - val_loss: 43.5606 - val_mean_absolute_error: 43.5606\n","\n","Epoch 00290: val_loss did not improve from 42.91207\n","Epoch 291/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.7564 - mean_absolute_error: 42.7564 - val_loss: 43.2180 - val_mean_absolute_error: 43.2180\n","\n","Epoch 00291: val_loss did not improve from 42.91207\n","Epoch 292/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.7523 - mean_absolute_error: 42.7523 - val_loss: 43.2316 - val_mean_absolute_error: 43.2316\n","\n","Epoch 00292: val_loss did not improve from 42.91207\n","Epoch 293/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8226 - mean_absolute_error: 42.8226 - val_loss: 43.4203 - val_mean_absolute_error: 43.4203\n","\n","Epoch 00293: val_loss did not improve from 42.91207\n","Epoch 294/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7307 - mean_absolute_error: 42.7307 - val_loss: 44.7476 - val_mean_absolute_error: 44.7476\n","\n","Epoch 00294: val_loss did not improve from 42.91207\n","Epoch 295/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9322 - mean_absolute_error: 42.9322 - val_loss: 43.0840 - val_mean_absolute_error: 43.0840\n","\n","Epoch 00295: val_loss did not improve from 42.91207\n","Epoch 296/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.6790 - mean_absolute_error: 42.6790 - val_loss: 45.0646 - val_mean_absolute_error: 45.0646\n","\n","Epoch 00296: val_loss did not improve from 42.91207\n","Epoch 297/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8403 - mean_absolute_error: 42.8403 - val_loss: 44.1180 - val_mean_absolute_error: 44.1180\n","\n","Epoch 00297: val_loss did not improve from 42.91207\n","Epoch 298/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6239 - mean_absolute_error: 42.6239 - val_loss: 44.0352 - val_mean_absolute_error: 44.0352\n","\n","Epoch 00298: val_loss did not improve from 42.91207\n","Epoch 299/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6896 - mean_absolute_error: 42.6896 - val_loss: 44.0865 - val_mean_absolute_error: 44.0865\n","\n","Epoch 00299: val_loss did not improve from 42.91207\n","Epoch 300/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9973 - mean_absolute_error: 42.9973 - val_loss: 43.4253 - val_mean_absolute_error: 43.4253\n","\n","Epoch 00300: val_loss did not improve from 42.91207\n","Epoch 301/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7404 - mean_absolute_error: 42.7404 - val_loss: 43.3349 - val_mean_absolute_error: 43.3349\n","\n","Epoch 00301: val_loss did not improve from 42.91207\n","Epoch 302/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6657 - mean_absolute_error: 42.6657 - val_loss: 44.0600 - val_mean_absolute_error: 44.0600\n","\n","Epoch 00302: val_loss did not improve from 42.91207\n","Epoch 303/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.7074 - mean_absolute_error: 42.7074 - val_loss: 43.7101 - val_mean_absolute_error: 43.7101\n","\n","Epoch 00303: val_loss did not improve from 42.91207\n","Epoch 304/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8399 - mean_absolute_error: 42.8399 - val_loss: 44.0669 - val_mean_absolute_error: 44.0669\n","\n","Epoch 00304: val_loss did not improve from 42.91207\n","Epoch 305/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.6925 - mean_absolute_error: 42.6925 - val_loss: 45.1113 - val_mean_absolute_error: 45.1113\n","\n","Epoch 00305: val_loss did not improve from 42.91207\n","Epoch 306/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9772 - mean_absolute_error: 42.9772 - val_loss: 43.0278 - val_mean_absolute_error: 43.0278\n","\n","Epoch 00306: val_loss did not improve from 42.91207\n","Epoch 307/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6595 - mean_absolute_error: 42.6595 - val_loss: 43.4059 - val_mean_absolute_error: 43.4059\n","\n","Epoch 00307: val_loss did not improve from 42.91207\n","Epoch 308/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 43.1045 - mean_absolute_error: 43.1045 - val_loss: 45.2707 - val_mean_absolute_error: 45.2707\n","\n","Epoch 00308: val_loss did not improve from 42.91207\n","Epoch 309/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.9366 - mean_absolute_error: 42.9366 - val_loss: 43.6224 - val_mean_absolute_error: 43.6224\n","\n","Epoch 00309: val_loss did not improve from 42.91207\n","Epoch 310/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8929 - mean_absolute_error: 42.8929 - val_loss: 44.5593 - val_mean_absolute_error: 44.5593\n","\n","Epoch 00310: val_loss did not improve from 42.91207\n","Epoch 311/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5589 - mean_absolute_error: 42.5589 - val_loss: 43.1666 - val_mean_absolute_error: 43.1666\n","\n","Epoch 00311: val_loss did not improve from 42.91207\n","Epoch 312/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7888 - mean_absolute_error: 42.7888 - val_loss: 43.6363 - val_mean_absolute_error: 43.6363\n","\n","Epoch 00312: val_loss did not improve from 42.91207\n","Epoch 313/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8791 - mean_absolute_error: 42.8791 - val_loss: 46.0277 - val_mean_absolute_error: 46.0277\n","\n","Epoch 00313: val_loss did not improve from 42.91207\n","Epoch 314/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.3193 - mean_absolute_error: 43.3193 - val_loss: 44.0289 - val_mean_absolute_error: 44.0289\n","\n","Epoch 00314: val_loss did not improve from 42.91207\n","Epoch 315/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9375 - mean_absolute_error: 42.9375 - val_loss: 43.8170 - val_mean_absolute_error: 43.8170\n","\n","Epoch 00315: val_loss did not improve from 42.91207\n","Epoch 316/500\n","10984/10984 [==============================] - 1s 121us/step - loss: 42.7184 - mean_absolute_error: 42.7184 - val_loss: 43.8013 - val_mean_absolute_error: 43.8013\n","\n","Epoch 00316: val_loss did not improve from 42.91207\n","Epoch 317/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8534 - mean_absolute_error: 42.8534 - val_loss: 44.7311 - val_mean_absolute_error: 44.7311\n","\n","Epoch 00317: val_loss did not improve from 42.91207\n","Epoch 318/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9170 - mean_absolute_error: 42.9170 - val_loss: 44.4133 - val_mean_absolute_error: 44.4133\n","\n","Epoch 00318: val_loss did not improve from 42.91207\n","Epoch 319/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6453 - mean_absolute_error: 42.6453 - val_loss: 43.0684 - val_mean_absolute_error: 43.0684\n","\n","Epoch 00319: val_loss did not improve from 42.91207\n","Epoch 320/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8056 - mean_absolute_error: 42.8056 - val_loss: 43.4511 - val_mean_absolute_error: 43.4511\n","\n","Epoch 00320: val_loss did not improve from 42.91207\n","Epoch 321/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9529 - mean_absolute_error: 42.9529 - val_loss: 45.3657 - val_mean_absolute_error: 45.3657\n","\n","Epoch 00321: val_loss did not improve from 42.91207\n","Epoch 322/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.7558 - mean_absolute_error: 42.7558 - val_loss: 43.1150 - val_mean_absolute_error: 43.1150\n","\n","Epoch 00322: val_loss did not improve from 42.91207\n","Epoch 323/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6566 - mean_absolute_error: 42.6566 - val_loss: 43.3866 - val_mean_absolute_error: 43.3866\n","\n","Epoch 00323: val_loss did not improve from 42.91207\n","Epoch 324/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.5823 - mean_absolute_error: 42.5823 - val_loss: 43.3373 - val_mean_absolute_error: 43.3373\n","\n","Epoch 00324: val_loss did not improve from 42.91207\n","Epoch 325/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.7786 - mean_absolute_error: 42.7786 - val_loss: 43.3872 - val_mean_absolute_error: 43.3872\n","\n","Epoch 00325: val_loss did not improve from 42.91207\n","Epoch 326/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8032 - mean_absolute_error: 42.8032 - val_loss: 47.1284 - val_mean_absolute_error: 47.1284\n","\n","Epoch 00326: val_loss did not improve from 42.91207\n","Epoch 327/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 43.2027 - mean_absolute_error: 43.2027 - val_loss: 43.9098 - val_mean_absolute_error: 43.9098\n","\n","Epoch 00327: val_loss did not improve from 42.91207\n","Epoch 328/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5949 - mean_absolute_error: 42.5949 - val_loss: 43.6148 - val_mean_absolute_error: 43.6148\n","\n","Epoch 00328: val_loss did not improve from 42.91207\n","Epoch 329/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6730 - mean_absolute_error: 42.6730 - val_loss: 43.4354 - val_mean_absolute_error: 43.4354\n","\n","Epoch 00329: val_loss did not improve from 42.91207\n","Epoch 330/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6885 - mean_absolute_error: 42.6885 - val_loss: 43.4328 - val_mean_absolute_error: 43.4328\n","\n","Epoch 00330: val_loss did not improve from 42.91207\n","Epoch 331/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6098 - mean_absolute_error: 42.6098 - val_loss: 43.8266 - val_mean_absolute_error: 43.8266\n","\n","Epoch 00331: val_loss did not improve from 42.91207\n","Epoch 332/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.7737 - mean_absolute_error: 42.7737 - val_loss: 42.8519 - val_mean_absolute_error: 42.8519\n","\n","Epoch 00332: val_loss improved from 42.91207 to 42.85191, saving model to /content/drive/ML/data-codenation-challenge/Weights-332--42.85191.hdf5\n","Epoch 333/500\n","10984/10984 [==============================] - 1s 124us/step - loss: 42.8397 - mean_absolute_error: 42.8397 - val_loss: 44.7971 - val_mean_absolute_error: 44.7971\n","\n","Epoch 00333: val_loss did not improve from 42.85191\n","Epoch 334/500\n","10984/10984 [==============================] - 2s 138us/step - loss: 42.5348 - mean_absolute_error: 42.5348 - val_loss: 43.1338 - val_mean_absolute_error: 43.1338\n","\n","Epoch 00334: val_loss did not improve from 42.85191\n","Epoch 335/500\n","10984/10984 [==============================] - 1s 136us/step - loss: 42.9479 - mean_absolute_error: 42.9479 - val_loss: 42.9210 - val_mean_absolute_error: 42.9210\n","\n","Epoch 00335: val_loss did not improve from 42.85191\n","Epoch 336/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 42.6667 - mean_absolute_error: 42.6667 - val_loss: 43.8815 - val_mean_absolute_error: 43.8815\n","\n","Epoch 00336: val_loss did not improve from 42.85191\n","Epoch 337/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 42.9609 - mean_absolute_error: 42.9609 - val_loss: 43.5085 - val_mean_absolute_error: 43.5085\n","\n","Epoch 00337: val_loss did not improve from 42.85191\n","Epoch 338/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 43.0988 - mean_absolute_error: 43.0988 - val_loss: 42.7829 - val_mean_absolute_error: 42.7829\n","\n","Epoch 00338: val_loss improved from 42.85191 to 42.78285, saving model to /content/drive/ML/data-codenation-challenge/Weights-338--42.78285.hdf5\n","Epoch 339/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6341 - mean_absolute_error: 42.6341 - val_loss: 44.0713 - val_mean_absolute_error: 44.0713\n","\n","Epoch 00339: val_loss did not improve from 42.78285\n","Epoch 340/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8264 - mean_absolute_error: 42.8264 - val_loss: 42.7512 - val_mean_absolute_error: 42.7512\n","\n","Epoch 00340: val_loss improved from 42.78285 to 42.75116, saving model to /content/drive/ML/data-codenation-challenge/Weights-340--42.75116.hdf5\n","Epoch 341/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4184 - mean_absolute_error: 42.4184 - val_loss: 45.4216 - val_mean_absolute_error: 45.4216\n","\n","Epoch 00341: val_loss did not improve from 42.75116\n","Epoch 342/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 43.4477 - mean_absolute_error: 43.4477 - val_loss: 43.4281 - val_mean_absolute_error: 43.4281\n","\n","Epoch 00342: val_loss did not improve from 42.75116\n","Epoch 343/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5783 - mean_absolute_error: 42.5783 - val_loss: 43.2172 - val_mean_absolute_error: 43.2172\n","\n","Epoch 00343: val_loss did not improve from 42.75116\n","Epoch 344/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6863 - mean_absolute_error: 42.6863 - val_loss: 43.0228 - val_mean_absolute_error: 43.0228\n","\n","Epoch 00344: val_loss did not improve from 42.75116\n","Epoch 345/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.6054 - mean_absolute_error: 42.6054 - val_loss: 44.0921 - val_mean_absolute_error: 44.0921\n","\n","Epoch 00345: val_loss did not improve from 42.75116\n","Epoch 346/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6974 - mean_absolute_error: 42.6974 - val_loss: 45.2885 - val_mean_absolute_error: 45.2885\n","\n","Epoch 00346: val_loss did not improve from 42.75116\n","Epoch 347/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.9976 - mean_absolute_error: 42.9976 - val_loss: 43.4745 - val_mean_absolute_error: 43.4745\n","\n","Epoch 00347: val_loss did not improve from 42.75116\n","Epoch 348/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.6961 - mean_absolute_error: 42.6961 - val_loss: 43.2322 - val_mean_absolute_error: 43.2322\n","\n","Epoch 00348: val_loss did not improve from 42.75116\n","Epoch 349/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4291 - mean_absolute_error: 42.4291 - val_loss: 43.3866 - val_mean_absolute_error: 43.3866\n","\n","Epoch 00349: val_loss did not improve from 42.75116\n","Epoch 350/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5391 - mean_absolute_error: 42.5391 - val_loss: 43.4461 - val_mean_absolute_error: 43.4461\n","\n","Epoch 00350: val_loss did not improve from 42.75116\n","Epoch 351/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6157 - mean_absolute_error: 42.6157 - val_loss: 43.6627 - val_mean_absolute_error: 43.6627\n","\n","Epoch 00351: val_loss did not improve from 42.75116\n","Epoch 352/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6005 - mean_absolute_error: 42.6005 - val_loss: 43.6526 - val_mean_absolute_error: 43.6526\n","\n","Epoch 00352: val_loss did not improve from 42.75116\n","Epoch 353/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7052 - mean_absolute_error: 42.7052 - val_loss: 43.7939 - val_mean_absolute_error: 43.7939\n","\n","Epoch 00353: val_loss did not improve from 42.75116\n","Epoch 354/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5622 - mean_absolute_error: 42.5622 - val_loss: 45.1900 - val_mean_absolute_error: 45.1900\n","\n","Epoch 00354: val_loss did not improve from 42.75116\n","Epoch 355/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6664 - mean_absolute_error: 42.6664 - val_loss: 43.1126 - val_mean_absolute_error: 43.1126\n","\n","Epoch 00355: val_loss did not improve from 42.75116\n","Epoch 356/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.9708 - mean_absolute_error: 42.9708 - val_loss: 44.6429 - val_mean_absolute_error: 44.6429\n","\n","Epoch 00356: val_loss did not improve from 42.75116\n","Epoch 357/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.3902 - mean_absolute_error: 42.3902 - val_loss: 43.1004 - val_mean_absolute_error: 43.1004\n","\n","Epoch 00357: val_loss did not improve from 42.75116\n","Epoch 358/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8245 - mean_absolute_error: 42.8245 - val_loss: 43.4914 - val_mean_absolute_error: 43.4914\n","\n","Epoch 00358: val_loss did not improve from 42.75116\n","Epoch 359/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.5664 - mean_absolute_error: 42.5664 - val_loss: 43.9248 - val_mean_absolute_error: 43.9248\n","\n","Epoch 00359: val_loss did not improve from 42.75116\n","Epoch 360/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.5295 - mean_absolute_error: 42.5295 - val_loss: 42.6965 - val_mean_absolute_error: 42.6965\n","\n","Epoch 00360: val_loss improved from 42.75116 to 42.69652, saving model to /content/drive/ML/data-codenation-challenge/Weights-360--42.69652.hdf5\n","Epoch 361/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7189 - mean_absolute_error: 42.7189 - val_loss: 43.4955 - val_mean_absolute_error: 43.4955\n","\n","Epoch 00361: val_loss did not improve from 42.69652\n","Epoch 362/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.6558 - mean_absolute_error: 42.6558 - val_loss: 44.3739 - val_mean_absolute_error: 44.3739\n","\n","Epoch 00362: val_loss did not improve from 42.69652\n","Epoch 363/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 42.5549 - mean_absolute_error: 42.5549 - val_loss: 43.5063 - val_mean_absolute_error: 43.5063\n","\n","Epoch 00363: val_loss did not improve from 42.69652\n","Epoch 364/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5198 - mean_absolute_error: 42.5198 - val_loss: 42.8956 - val_mean_absolute_error: 42.8956\n","\n","Epoch 00364: val_loss did not improve from 42.69652\n","Epoch 365/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6125 - mean_absolute_error: 42.6125 - val_loss: 43.4330 - val_mean_absolute_error: 43.4330\n","\n","Epoch 00365: val_loss did not improve from 42.69652\n","Epoch 366/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.3983 - mean_absolute_error: 42.3983 - val_loss: 43.5647 - val_mean_absolute_error: 43.5647\n","\n","Epoch 00366: val_loss did not improve from 42.69652\n","Epoch 367/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.8867 - mean_absolute_error: 42.8867 - val_loss: 45.9046 - val_mean_absolute_error: 45.9046\n","\n","Epoch 00367: val_loss did not improve from 42.69652\n","Epoch 368/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.3711 - mean_absolute_error: 42.3711 - val_loss: 43.5249 - val_mean_absolute_error: 43.5249\n","\n","Epoch 00368: val_loss did not improve from 42.69652\n","Epoch 369/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4936 - mean_absolute_error: 42.4936 - val_loss: 42.7891 - val_mean_absolute_error: 42.7891\n","\n","Epoch 00369: val_loss did not improve from 42.69652\n","Epoch 370/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.3485 - mean_absolute_error: 42.3485 - val_loss: 42.8414 - val_mean_absolute_error: 42.8414\n","\n","Epoch 00370: val_loss did not improve from 42.69652\n","Epoch 371/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 43.0058 - mean_absolute_error: 43.0058 - val_loss: 43.5415 - val_mean_absolute_error: 43.5415\n","\n","Epoch 00371: val_loss did not improve from 42.69652\n","Epoch 372/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 43.1324 - mean_absolute_error: 43.1324 - val_loss: 43.5581 - val_mean_absolute_error: 43.5581\n","\n","Epoch 00372: val_loss did not improve from 42.69652\n","Epoch 373/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.3830 - mean_absolute_error: 42.3830 - val_loss: 43.4158 - val_mean_absolute_error: 43.4158\n","\n","Epoch 00373: val_loss did not improve from 42.69652\n","Epoch 374/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.9252 - mean_absolute_error: 42.9252 - val_loss: 44.6125 - val_mean_absolute_error: 44.6125\n","\n","Epoch 00374: val_loss did not improve from 42.69652\n","Epoch 375/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5944 - mean_absolute_error: 42.5944 - val_loss: 44.5380 - val_mean_absolute_error: 44.5380\n","\n","Epoch 00375: val_loss did not improve from 42.69652\n","Epoch 376/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 42.3761 - mean_absolute_error: 42.3761 - val_loss: 43.9883 - val_mean_absolute_error: 43.9883\n","\n","Epoch 00376: val_loss did not improve from 42.69652\n","Epoch 377/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7962 - mean_absolute_error: 42.7962 - val_loss: 42.9823 - val_mean_absolute_error: 42.9823\n","\n","Epoch 00377: val_loss did not improve from 42.69652\n","Epoch 378/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.7595 - mean_absolute_error: 42.7595 - val_loss: 42.9132 - val_mean_absolute_error: 42.9132\n","\n","Epoch 00378: val_loss did not improve from 42.69652\n","Epoch 379/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6745 - mean_absolute_error: 42.6745 - val_loss: 42.9135 - val_mean_absolute_error: 42.9135\n","\n","Epoch 00379: val_loss did not improve from 42.69652\n","Epoch 380/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.5805 - mean_absolute_error: 42.5805 - val_loss: 44.3888 - val_mean_absolute_error: 44.3888\n","\n","Epoch 00380: val_loss did not improve from 42.69652\n","Epoch 381/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 42.4328 - mean_absolute_error: 42.4328 - val_loss: 44.5776 - val_mean_absolute_error: 44.5776\n","\n","Epoch 00381: val_loss did not improve from 42.69652\n","Epoch 382/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.4608 - mean_absolute_error: 42.4608 - val_loss: 43.1822 - val_mean_absolute_error: 43.1822\n","\n","Epoch 00382: val_loss did not improve from 42.69652\n","Epoch 383/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5779 - mean_absolute_error: 42.5779 - val_loss: 42.7985 - val_mean_absolute_error: 42.7985\n","\n","Epoch 00383: val_loss did not improve from 42.69652\n","Epoch 384/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.6523 - mean_absolute_error: 42.6523 - val_loss: 43.3521 - val_mean_absolute_error: 43.3521\n","\n","Epoch 00384: val_loss did not improve from 42.69652\n","Epoch 385/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2726 - mean_absolute_error: 42.2726 - val_loss: 43.9462 - val_mean_absolute_error: 43.9462\n","\n","Epoch 00385: val_loss did not improve from 42.69652\n","Epoch 386/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.4676 - mean_absolute_error: 42.4676 - val_loss: 42.8946 - val_mean_absolute_error: 42.8946\n","\n","Epoch 00386: val_loss did not improve from 42.69652\n","Epoch 387/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.4057 - mean_absolute_error: 42.4057 - val_loss: 43.0842 - val_mean_absolute_error: 43.0842\n","\n","Epoch 00387: val_loss did not improve from 42.69652\n","Epoch 388/500\n","10984/10984 [==============================] - 1s 124us/step - loss: 42.6063 - mean_absolute_error: 42.6063 - val_loss: 44.0287 - val_mean_absolute_error: 44.0287\n","\n","Epoch 00388: val_loss did not improve from 42.69652\n","Epoch 389/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 42.9074 - mean_absolute_error: 42.9074 - val_loss: 43.2132 - val_mean_absolute_error: 43.2132\n","\n","Epoch 00389: val_loss did not improve from 42.69652\n","Epoch 390/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 42.4844 - mean_absolute_error: 42.4844 - val_loss: 43.1378 - val_mean_absolute_error: 43.1378\n","\n","Epoch 00390: val_loss did not improve from 42.69652\n","Epoch 391/500\n","10984/10984 [==============================] - 2s 139us/step - loss: 42.4023 - mean_absolute_error: 42.4023 - val_loss: 43.6144 - val_mean_absolute_error: 43.6144\n","\n","Epoch 00391: val_loss did not improve from 42.69652\n","Epoch 392/500\n","10984/10984 [==============================] - 2s 143us/step - loss: 42.5565 - mean_absolute_error: 42.5565 - val_loss: 42.7428 - val_mean_absolute_error: 42.7428\n","\n","Epoch 00392: val_loss did not improve from 42.69652\n","Epoch 393/500\n","10984/10984 [==============================] - 2s 142us/step - loss: 42.3386 - mean_absolute_error: 42.3386 - val_loss: 43.1891 - val_mean_absolute_error: 43.1891\n","\n","Epoch 00393: val_loss did not improve from 42.69652\n","Epoch 394/500\n","10984/10984 [==============================] - 2s 142us/step - loss: 42.5698 - mean_absolute_error: 42.5698 - val_loss: 43.2079 - val_mean_absolute_error: 43.2079\n","\n","Epoch 00394: val_loss did not improve from 42.69652\n","Epoch 395/500\n","10984/10984 [==============================] - 1s 125us/step - loss: 42.3175 - mean_absolute_error: 42.3175 - val_loss: 43.3189 - val_mean_absolute_error: 43.3189\n","\n","Epoch 00395: val_loss did not improve from 42.69652\n","Epoch 396/500\n","10984/10984 [==============================] - 1s 123us/step - loss: 42.3834 - mean_absolute_error: 42.3834 - val_loss: 43.5447 - val_mean_absolute_error: 43.5447\n","\n","Epoch 00396: val_loss did not improve from 42.69652\n","Epoch 397/500\n","10984/10984 [==============================] - 2s 143us/step - loss: 42.8042 - mean_absolute_error: 42.8042 - val_loss: 43.2500 - val_mean_absolute_error: 43.2500\n","\n","Epoch 00397: val_loss did not improve from 42.69652\n","Epoch 398/500\n","10984/10984 [==============================] - 2s 143us/step - loss: 42.7462 - mean_absolute_error: 42.7462 - val_loss: 43.6217 - val_mean_absolute_error: 43.6217\n","\n","Epoch 00398: val_loss did not improve from 42.69652\n","Epoch 399/500\n","10984/10984 [==============================] - 2s 144us/step - loss: 42.4075 - mean_absolute_error: 42.4075 - val_loss: 44.2281 - val_mean_absolute_error: 44.2281\n","\n","Epoch 00399: val_loss did not improve from 42.69652\n","Epoch 400/500\n","10984/10984 [==============================] - 2s 148us/step - loss: 42.7395 - mean_absolute_error: 42.7395 - val_loss: 43.6559 - val_mean_absolute_error: 43.6559\n","\n","Epoch 00400: val_loss did not improve from 42.69652\n","Epoch 401/500\n","10984/10984 [==============================] - 2s 142us/step - loss: 42.4424 - mean_absolute_error: 42.4424 - val_loss: 43.1919 - val_mean_absolute_error: 43.1919\n","\n","Epoch 00401: val_loss did not improve from 42.69652\n","Epoch 402/500\n","10984/10984 [==============================] - 2s 143us/step - loss: 42.5777 - mean_absolute_error: 42.5777 - val_loss: 43.0185 - val_mean_absolute_error: 43.0185\n","\n","Epoch 00402: val_loss did not improve from 42.69652\n","Epoch 403/500\n","10984/10984 [==============================] - 1s 124us/step - loss: 42.2482 - mean_absolute_error: 42.2482 - val_loss: 43.3170 - val_mean_absolute_error: 43.3170\n","\n","Epoch 00403: val_loss did not improve from 42.69652\n","Epoch 404/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.5448 - mean_absolute_error: 42.5448 - val_loss: 43.0054 - val_mean_absolute_error: 43.0054\n","\n","Epoch 00404: val_loss did not improve from 42.69652\n","Epoch 405/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4373 - mean_absolute_error: 42.4373 - val_loss: 43.7870 - val_mean_absolute_error: 43.7870\n","\n","Epoch 00405: val_loss did not improve from 42.69652\n","Epoch 406/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.2942 - mean_absolute_error: 42.2942 - val_loss: 44.1998 - val_mean_absolute_error: 44.1998\n","\n","Epoch 00406: val_loss did not improve from 42.69652\n","Epoch 407/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.5338 - mean_absolute_error: 42.5338 - val_loss: 44.1186 - val_mean_absolute_error: 44.1186\n","\n","Epoch 00407: val_loss did not improve from 42.69652\n","Epoch 408/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.0568 - mean_absolute_error: 42.0568 - val_loss: 47.7565 - val_mean_absolute_error: 47.7565\n","\n","Epoch 00408: val_loss did not improve from 42.69652\n","Epoch 409/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6917 - mean_absolute_error: 42.6917 - val_loss: 43.1154 - val_mean_absolute_error: 43.1154\n","\n","Epoch 00409: val_loss did not improve from 42.69652\n","Epoch 410/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.3959 - mean_absolute_error: 42.3959 - val_loss: 46.1672 - val_mean_absolute_error: 46.1672\n","\n","Epoch 00410: val_loss did not improve from 42.69652\n","Epoch 411/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.4601 - mean_absolute_error: 42.4601 - val_loss: 44.5136 - val_mean_absolute_error: 44.5136\n","\n","Epoch 00411: val_loss did not improve from 42.69652\n","Epoch 412/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.5017 - mean_absolute_error: 42.5017 - val_loss: 42.8856 - val_mean_absolute_error: 42.8856\n","\n","Epoch 00412: val_loss did not improve from 42.69652\n","Epoch 413/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4636 - mean_absolute_error: 42.4636 - val_loss: 43.0079 - val_mean_absolute_error: 43.0079\n","\n","Epoch 00413: val_loss did not improve from 42.69652\n","Epoch 414/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 42.4640 - mean_absolute_error: 42.4640 - val_loss: 43.2961 - val_mean_absolute_error: 43.2961\n","\n","Epoch 00414: val_loss did not improve from 42.69652\n","Epoch 415/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.2975 - mean_absolute_error: 42.2975 - val_loss: 43.5702 - val_mean_absolute_error: 43.5702\n","\n","Epoch 00415: val_loss did not improve from 42.69652\n","Epoch 416/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6246 - mean_absolute_error: 42.6246 - val_loss: 43.9910 - val_mean_absolute_error: 43.9910\n","\n","Epoch 00416: val_loss did not improve from 42.69652\n","Epoch 417/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.2695 - mean_absolute_error: 42.2695 - val_loss: 43.1309 - val_mean_absolute_error: 43.1309\n","\n","Epoch 00417: val_loss did not improve from 42.69652\n","Epoch 418/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.3189 - mean_absolute_error: 42.3189 - val_loss: 44.8464 - val_mean_absolute_error: 44.8464\n","\n","Epoch 00418: val_loss did not improve from 42.69652\n","Epoch 419/500\n","10984/10984 [==============================] - 1s 116us/step - loss: 42.2605 - mean_absolute_error: 42.2605 - val_loss: 44.9641 - val_mean_absolute_error: 44.9641\n","\n","Epoch 00419: val_loss did not improve from 42.69652\n","Epoch 420/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.3856 - mean_absolute_error: 42.3856 - val_loss: 44.3118 - val_mean_absolute_error: 44.3118\n","\n","Epoch 00420: val_loss did not improve from 42.69652\n","Epoch 421/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2454 - mean_absolute_error: 42.2454 - val_loss: 45.0557 - val_mean_absolute_error: 45.0557\n","\n","Epoch 00421: val_loss did not improve from 42.69652\n","Epoch 422/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.5247 - mean_absolute_error: 42.5247 - val_loss: 43.3569 - val_mean_absolute_error: 43.3569\n","\n","Epoch 00422: val_loss did not improve from 42.69652\n","Epoch 423/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.0959 - mean_absolute_error: 42.0959 - val_loss: 44.2788 - val_mean_absolute_error: 44.2788\n","\n","Epoch 00423: val_loss did not improve from 42.69652\n","Epoch 424/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.8267 - mean_absolute_error: 42.8267 - val_loss: 43.5151 - val_mean_absolute_error: 43.5151\n","\n","Epoch 00424: val_loss did not improve from 42.69652\n","Epoch 425/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.3882 - mean_absolute_error: 42.3882 - val_loss: 42.9174 - val_mean_absolute_error: 42.9174\n","\n","Epoch 00425: val_loss did not improve from 42.69652\n","Epoch 426/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5764 - mean_absolute_error: 42.5764 - val_loss: 43.1545 - val_mean_absolute_error: 43.1545\n","\n","Epoch 00426: val_loss did not improve from 42.69652\n","Epoch 427/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2777 - mean_absolute_error: 42.2777 - val_loss: 44.1006 - val_mean_absolute_error: 44.1006\n","\n","Epoch 00427: val_loss did not improve from 42.69652\n","Epoch 428/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.4500 - mean_absolute_error: 42.4500 - val_loss: 43.8171 - val_mean_absolute_error: 43.8171\n","\n","Epoch 00428: val_loss did not improve from 42.69652\n","Epoch 429/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.2474 - mean_absolute_error: 42.2474 - val_loss: 42.8366 - val_mean_absolute_error: 42.8366\n","\n","Epoch 00429: val_loss did not improve from 42.69652\n","Epoch 430/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.5751 - mean_absolute_error: 42.5751 - val_loss: 43.3330 - val_mean_absolute_error: 43.3330\n","\n","Epoch 00430: val_loss did not improve from 42.69652\n","Epoch 431/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4380 - mean_absolute_error: 42.4380 - val_loss: 43.0716 - val_mean_absolute_error: 43.0716\n","\n","Epoch 00431: val_loss did not improve from 42.69652\n","Epoch 432/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.3872 - mean_absolute_error: 42.3872 - val_loss: 43.9384 - val_mean_absolute_error: 43.9384\n","\n","Epoch 00432: val_loss did not improve from 42.69652\n","Epoch 433/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.5439 - mean_absolute_error: 42.5439 - val_loss: 44.6637 - val_mean_absolute_error: 44.6637\n","\n","Epoch 00433: val_loss did not improve from 42.69652\n","Epoch 434/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2769 - mean_absolute_error: 42.2769 - val_loss: 43.0349 - val_mean_absolute_error: 43.0349\n","\n","Epoch 00434: val_loss did not improve from 42.69652\n","Epoch 435/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.4776 - mean_absolute_error: 42.4776 - val_loss: 43.1022 - val_mean_absolute_error: 43.1022\n","\n","Epoch 00435: val_loss did not improve from 42.69652\n","Epoch 436/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.5047 - mean_absolute_error: 42.5047 - val_loss: 48.0318 - val_mean_absolute_error: 48.0318\n","\n","Epoch 00436: val_loss did not improve from 42.69652\n","Epoch 437/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.4274 - mean_absolute_error: 42.4274 - val_loss: 43.1375 - val_mean_absolute_error: 43.1375\n","\n","Epoch 00437: val_loss did not improve from 42.69652\n","Epoch 438/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.4118 - mean_absolute_error: 42.4118 - val_loss: 42.9898 - val_mean_absolute_error: 42.9898\n","\n","Epoch 00438: val_loss did not improve from 42.69652\n","Epoch 439/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.2250 - mean_absolute_error: 42.2250 - val_loss: 42.9520 - val_mean_absolute_error: 42.9520\n","\n","Epoch 00439: val_loss did not improve from 42.69652\n","Epoch 440/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.0466 - mean_absolute_error: 42.0466 - val_loss: 43.0770 - val_mean_absolute_error: 43.0770\n","\n","Epoch 00440: val_loss did not improve from 42.69652\n","Epoch 441/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.2936 - mean_absolute_error: 42.2936 - val_loss: 43.1856 - val_mean_absolute_error: 43.1856\n","\n","Epoch 00441: val_loss did not improve from 42.69652\n","Epoch 442/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.3832 - mean_absolute_error: 42.3832 - val_loss: 42.8934 - val_mean_absolute_error: 42.8934\n","\n","Epoch 00442: val_loss did not improve from 42.69652\n","Epoch 443/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.2159 - mean_absolute_error: 42.2159 - val_loss: 43.4990 - val_mean_absolute_error: 43.4990\n","\n","Epoch 00443: val_loss did not improve from 42.69652\n","Epoch 444/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2426 - mean_absolute_error: 42.2426 - val_loss: 44.9788 - val_mean_absolute_error: 44.9788\n","\n","Epoch 00444: val_loss did not improve from 42.69652\n","Epoch 445/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.4223 - mean_absolute_error: 42.4223 - val_loss: 44.3669 - val_mean_absolute_error: 44.3669\n","\n","Epoch 00445: val_loss did not improve from 42.69652\n","Epoch 446/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2482 - mean_absolute_error: 42.2482 - val_loss: 44.8146 - val_mean_absolute_error: 44.8146\n","\n","Epoch 00446: val_loss did not improve from 42.69652\n","Epoch 447/500\n","10984/10984 [==============================] - 1s 121us/step - loss: 42.7454 - mean_absolute_error: 42.7454 - val_loss: 44.4451 - val_mean_absolute_error: 44.4451\n","\n","Epoch 00447: val_loss did not improve from 42.69652\n","Epoch 448/500\n","10984/10984 [==============================] - 1s 134us/step - loss: 42.0547 - mean_absolute_error: 42.0547 - val_loss: 43.6299 - val_mean_absolute_error: 43.6299\n","\n","Epoch 00448: val_loss did not improve from 42.69652\n","Epoch 449/500\n","10984/10984 [==============================] - 2s 140us/step - loss: 42.3541 - mean_absolute_error: 42.3541 - val_loss: 42.9138 - val_mean_absolute_error: 42.9138\n","\n","Epoch 00449: val_loss did not improve from 42.69652\n","Epoch 450/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 42.5301 - mean_absolute_error: 42.5301 - val_loss: 43.2949 - val_mean_absolute_error: 43.2949\n","\n","Epoch 00450: val_loss did not improve from 42.69652\n","Epoch 451/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 42.5036 - mean_absolute_error: 42.5036 - val_loss: 44.5286 - val_mean_absolute_error: 44.5286\n","\n","Epoch 00451: val_loss did not improve from 42.69652\n","Epoch 452/500\n","10984/10984 [==============================] - 2s 137us/step - loss: 42.4335 - mean_absolute_error: 42.4335 - val_loss: 42.7917 - val_mean_absolute_error: 42.7917\n","\n","Epoch 00452: val_loss did not improve from 42.69652\n","Epoch 453/500\n","10984/10984 [==============================] - 1s 137us/step - loss: 42.3314 - mean_absolute_error: 42.3314 - val_loss: 42.7833 - val_mean_absolute_error: 42.7833\n","\n","Epoch 00453: val_loss did not improve from 42.69652\n","Epoch 454/500\n","10984/10984 [==============================] - 1s 134us/step - loss: 42.2762 - mean_absolute_error: 42.2762 - val_loss: 42.9737 - val_mean_absolute_error: 42.9737\n","\n","Epoch 00454: val_loss did not improve from 42.69652\n","Epoch 455/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2590 - mean_absolute_error: 42.2590 - val_loss: 43.5877 - val_mean_absolute_error: 43.5877\n","\n","Epoch 00455: val_loss did not improve from 42.69652\n","Epoch 456/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.2629 - mean_absolute_error: 42.2629 - val_loss: 43.4823 - val_mean_absolute_error: 43.4823\n","\n","Epoch 00456: val_loss did not improve from 42.69652\n","Epoch 457/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.0583 - mean_absolute_error: 42.0583 - val_loss: 43.1854 - val_mean_absolute_error: 43.1854\n","\n","Epoch 00457: val_loss did not improve from 42.69652\n","Epoch 458/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2595 - mean_absolute_error: 42.2595 - val_loss: 42.7056 - val_mean_absolute_error: 42.7056\n","\n","Epoch 00458: val_loss did not improve from 42.69652\n","Epoch 459/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1520 - mean_absolute_error: 42.1520 - val_loss: 43.8484 - val_mean_absolute_error: 43.8484\n","\n","Epoch 00459: val_loss did not improve from 42.69652\n","Epoch 460/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2850 - mean_absolute_error: 42.2850 - val_loss: 42.7882 - val_mean_absolute_error: 42.7882\n","\n","Epoch 00460: val_loss did not improve from 42.69652\n","Epoch 461/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4669 - mean_absolute_error: 42.4669 - val_loss: 44.3511 - val_mean_absolute_error: 44.3511\n","\n","Epoch 00461: val_loss did not improve from 42.69652\n","Epoch 462/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.3718 - mean_absolute_error: 42.3718 - val_loss: 43.4208 - val_mean_absolute_error: 43.4208\n","\n","Epoch 00462: val_loss did not improve from 42.69652\n","Epoch 463/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.0684 - mean_absolute_error: 42.0684 - val_loss: 44.0573 - val_mean_absolute_error: 44.0573\n","\n","Epoch 00463: val_loss did not improve from 42.69652\n","Epoch 464/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.3723 - mean_absolute_error: 42.3723 - val_loss: 47.6591 - val_mean_absolute_error: 47.6591\n","\n","Epoch 00464: val_loss did not improve from 42.69652\n","Epoch 465/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.3906 - mean_absolute_error: 42.3906 - val_loss: 45.2216 - val_mean_absolute_error: 45.2216\n","\n","Epoch 00465: val_loss did not improve from 42.69652\n","Epoch 466/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.5091 - mean_absolute_error: 42.5091 - val_loss: 42.9626 - val_mean_absolute_error: 42.9626\n","\n","Epoch 00466: val_loss did not improve from 42.69652\n","Epoch 467/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4604 - mean_absolute_error: 42.4604 - val_loss: 42.9786 - val_mean_absolute_error: 42.9786\n","\n","Epoch 00467: val_loss did not improve from 42.69652\n","Epoch 468/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.2691 - mean_absolute_error: 42.2691 - val_loss: 44.4326 - val_mean_absolute_error: 44.4326\n","\n","Epoch 00468: val_loss did not improve from 42.69652\n","Epoch 469/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.6571 - mean_absolute_error: 42.6571 - val_loss: 43.4526 - val_mean_absolute_error: 43.4526\n","\n","Epoch 00469: val_loss did not improve from 42.69652\n","Epoch 470/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.1275 - mean_absolute_error: 42.1275 - val_loss: 43.1680 - val_mean_absolute_error: 43.1680\n","\n","Epoch 00470: val_loss did not improve from 42.69652\n","Epoch 471/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4461 - mean_absolute_error: 42.4461 - val_loss: 44.4161 - val_mean_absolute_error: 44.4161\n","\n","Epoch 00471: val_loss did not improve from 42.69652\n","Epoch 472/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.0914 - mean_absolute_error: 42.0914 - val_loss: 43.4407 - val_mean_absolute_error: 43.4407\n","\n","Epoch 00472: val_loss did not improve from 42.69652\n","Epoch 473/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1368 - mean_absolute_error: 42.1368 - val_loss: 43.5223 - val_mean_absolute_error: 43.5223\n","\n","Epoch 00473: val_loss did not improve from 42.69652\n","Epoch 474/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1972 - mean_absolute_error: 42.1972 - val_loss: 43.6877 - val_mean_absolute_error: 43.6877\n","\n","Epoch 00474: val_loss did not improve from 42.69652\n","Epoch 475/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.4286 - mean_absolute_error: 42.4286 - val_loss: 43.2185 - val_mean_absolute_error: 43.2185\n","\n","Epoch 00475: val_loss did not improve from 42.69652\n","Epoch 476/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.2411 - mean_absolute_error: 42.2411 - val_loss: 43.4670 - val_mean_absolute_error: 43.4670\n","\n","Epoch 00476: val_loss did not improve from 42.69652\n","Epoch 477/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4679 - mean_absolute_error: 42.4679 - val_loss: 44.4471 - val_mean_absolute_error: 44.4471\n","\n","Epoch 00477: val_loss did not improve from 42.69652\n","Epoch 478/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.1558 - mean_absolute_error: 42.1558 - val_loss: 42.7714 - val_mean_absolute_error: 42.7714\n","\n","Epoch 00478: val_loss did not improve from 42.69652\n","Epoch 479/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.0212 - mean_absolute_error: 42.0212 - val_loss: 42.6845 - val_mean_absolute_error: 42.6845\n","\n","Epoch 00479: val_loss improved from 42.69652 to 42.68452, saving model to /content/drive/ML/data-codenation-challenge/Weights-479--42.68452.hdf5\n","Epoch 480/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1909 - mean_absolute_error: 42.1909 - val_loss: 43.1800 - val_mean_absolute_error: 43.1800\n","\n","Epoch 00480: val_loss did not improve from 42.68452\n","Epoch 481/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4036 - mean_absolute_error: 42.4036 - val_loss: 43.7163 - val_mean_absolute_error: 43.7163\n","\n","Epoch 00481: val_loss did not improve from 42.68452\n","Epoch 482/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.0391 - mean_absolute_error: 42.0391 - val_loss: 43.3081 - val_mean_absolute_error: 43.3081\n","\n","Epoch 00482: val_loss did not improve from 42.68452\n","Epoch 483/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4072 - mean_absolute_error: 42.4072 - val_loss: 43.6294 - val_mean_absolute_error: 43.6294\n","\n","Epoch 00483: val_loss did not improve from 42.68452\n","Epoch 484/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.4898 - mean_absolute_error: 42.4898 - val_loss: 43.0960 - val_mean_absolute_error: 43.0960\n","\n","Epoch 00484: val_loss did not improve from 42.68452\n","Epoch 485/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.2039 - mean_absolute_error: 42.2039 - val_loss: 42.8110 - val_mean_absolute_error: 42.8110\n","\n","Epoch 00485: val_loss did not improve from 42.68452\n","Epoch 486/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1466 - mean_absolute_error: 42.1466 - val_loss: 44.7080 - val_mean_absolute_error: 44.7080\n","\n","Epoch 00486: val_loss did not improve from 42.68452\n","Epoch 487/500\n","10984/10984 [==============================] - 1s 120us/step - loss: 42.0126 - mean_absolute_error: 42.0126 - val_loss: 44.9748 - val_mean_absolute_error: 44.9748\n","\n","Epoch 00487: val_loss did not improve from 42.68452\n","Epoch 488/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.3311 - mean_absolute_error: 42.3311 - val_loss: 42.8141 - val_mean_absolute_error: 42.8141\n","\n","Epoch 00488: val_loss did not improve from 42.68452\n","Epoch 489/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.3780 - mean_absolute_error: 42.3780 - val_loss: 43.1205 - val_mean_absolute_error: 43.1205\n","\n","Epoch 00489: val_loss did not improve from 42.68452\n","Epoch 490/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1293 - mean_absolute_error: 42.1293 - val_loss: 43.6499 - val_mean_absolute_error: 43.6499\n","\n","Epoch 00490: val_loss did not improve from 42.68452\n","Epoch 491/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.1963 - mean_absolute_error: 42.1963 - val_loss: 44.1960 - val_mean_absolute_error: 44.1960\n","\n","Epoch 00491: val_loss did not improve from 42.68452\n","Epoch 492/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.1897 - mean_absolute_error: 42.1897 - val_loss: 43.2984 - val_mean_absolute_error: 43.2984\n","\n","Epoch 00492: val_loss did not improve from 42.68452\n","Epoch 493/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1639 - mean_absolute_error: 42.1639 - val_loss: 43.5815 - val_mean_absolute_error: 43.5815\n","\n","Epoch 00493: val_loss did not improve from 42.68452\n","Epoch 494/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.2699 - mean_absolute_error: 42.2699 - val_loss: 43.6425 - val_mean_absolute_error: 43.6425\n","\n","Epoch 00494: val_loss did not improve from 42.68452\n","Epoch 495/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.0274 - mean_absolute_error: 42.0274 - val_loss: 43.2711 - val_mean_absolute_error: 43.2711\n","\n","Epoch 00495: val_loss did not improve from 42.68452\n","Epoch 496/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1701 - mean_absolute_error: 42.1701 - val_loss: 44.7769 - val_mean_absolute_error: 44.7769\n","\n","Epoch 00496: val_loss did not improve from 42.68452\n","Epoch 497/500\n","10984/10984 [==============================] - 1s 117us/step - loss: 42.3527 - mean_absolute_error: 42.3527 - val_loss: 44.1580 - val_mean_absolute_error: 44.1580\n","\n","Epoch 00497: val_loss did not improve from 42.68452\n","Epoch 498/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.4267 - mean_absolute_error: 42.4267 - val_loss: 45.2214 - val_mean_absolute_error: 45.2214\n","\n","Epoch 00498: val_loss did not improve from 42.68452\n","Epoch 499/500\n","10984/10984 [==============================] - 1s 118us/step - loss: 42.1037 - mean_absolute_error: 42.1037 - val_loss: 42.8402 - val_mean_absolute_error: 42.8402\n","\n","Epoch 00499: val_loss did not improve from 42.68452\n","Epoch 500/500\n","10984/10984 [==============================] - 1s 119us/step - loss: 42.3598 - mean_absolute_error: 42.3598 - val_loss: 43.4300 - val_mean_absolute_error: 43.4300\n","\n","Epoch 00500: val_loss did not improve from 42.68452\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f55cd7b7d68>"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"e7pv7BC1sOWg","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load wights file of the best model :\n","wights_file = '/content/drive/ML/data-codenation-challenge/Weights-479--42.68452.hdf5' # choose the best checkpoint \n","NN_model.load_weights(wights_file) # load it\n","NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"prVQj6UWsPN9","colab_type":"code","colab":{}},"cell_type":"code","source":["predictions = NN_model.predict(df_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8SpGW6y_sctM","colab_type":"code","colab":{}},"cell_type":"code","source":["df_answer['NU_NOTA_MT'] = np.around(predictions,2)\n","\n","df_answer.to_csv('/content/drive/ML/data-codenation-challenge/dnn_answer.csv', index=False, header=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dtc1HOWt--ZF","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_to_zero(filename):\n","\n","\tdata = pd.read_csv(filename+'.csv')\n","\n","\tfor i in range(0, data.shape[0]):\n","\t\tif data['NU_NOTA_MT'][i] < 80:\n","\t\t\tdata['NU_NOTA_MT'][i] = 0.00\n","\n","\tdata.to_csv('/content/drive/ML/data-codenation-challenge/xgb_dnn.csv', index=False, header=True)\n","\n","\treturn data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2TDlPaGS_5Sf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"5e5289d8-9bff-4148-a831-39dd0f3d7045","executionInfo":{"status":"ok","timestamp":1556036511914,"user_tz":180,"elapsed":50249,"user":{"displayName":"João Vitor Ferreira França","photoUrl":"","userId":"03674045354190356741"}}},"cell_type":"code","source":["XGBModel = XGBRegressor()\n","XGBModel.fit(df_train,label, verbose=False)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bytree=1, gamma=0, importance_type='gain',\n","       learning_rate=0.1, max_delta_step=0, max_depth=3,\n","       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n","       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n","       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n","       subsample=1)"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"JSdhyRMzADnf","colab_type":"code","colab":{}},"cell_type":"code","source":["XGBpredictions = XGBModel.predict(df_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZccHxmiqARaX","colab_type":"code","colab":{}},"cell_type":"code","source":["df_answer['NU_NOTA_MT'] = np.around(XGBpredictions,2)\n","\n","df_answer.to_csv('/content/drive/ML/data-codenation-challenge/xgb_answer.csv', index=False, header=True)\n","\n","data = convert_to_zero('/content/drive/ML/data-codenation-challenge/xgb_answer')"],"execution_count":0,"outputs":[]}]}